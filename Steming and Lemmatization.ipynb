{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "959d6692",
   "metadata": {},
   "source": [
    "# <font color='blue'> Stemming </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2272739a",
   "metadata": {},
   "source": [
    "**Stemming is the process of producing morphological variants of a root/base word. Stemming programs are commonly referred to as stemming algorithms or stemmers. A stemming algorithm reduces the words “chocolates”, “chocolatey”, and “choco” to the root word, “chocolate” and “retrieval”, “retrieved”, “retrieves” reduce to the stem “retrieve”.**"
   ]
  },
  {
   "cell_type": "raw",
   "id": "458817fa",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c821a78b",
   "metadata": {},
   "source": [
    "**Spacy** doesn't include Stemmer instead it relies on Lemmatization so we will use NLTK here"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0bb02269",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be9e354f",
   "metadata": {},
   "source": [
    "**Lets discuss 2 type of Stemmers** <br>\n",
    "1. PortalStemmer\n",
    "2. SnowballStemmer"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ced891b1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "831e45c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d374f0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30715962",
   "metadata": {},
   "outputs": [],
   "source": [
    "p=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59b5fc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "words=['help','helping','helps','helpful','helped','finally','final']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27f904bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "help ------>>>    help\n",
      "helping ------>>>    help\n",
      "helps ------>>>    help\n",
      "helpful ------>>>    help\n",
      "helped ------>>>    help\n",
      "finally ------>>>    final\n",
      "final ------>>>    final\n"
     ]
    }
   ],
   "source": [
    "for w in words:\n",
    "    print(f\"{w} ------>>>    {p.stem(w)}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "30933efa",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b95264c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65dae7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "s=SnowballStemmer(language='english')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5ccb2b",
   "metadata": {},
   "source": [
    "Arabic, Danish, Dutch, English, Finnish, French, German,<br>\n",
    "Hungarian, Italian, Norwegian, Portuguese, Romanian, Russian,<br>\n",
    "Spanish and Swedish"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da662ea",
   "metadata": {},
   "source": [
    "**There are type of languages which you can use from SnowballStemmer you can also check by pressing shift Tab inside the parenthesis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb9a9216",
   "metadata": {},
   "outputs": [],
   "source": [
    "words=['help','helping','helps','helpful','helped','finally','final']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1bb4f9e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "help ------>>>    help\n",
      "helping ------>>>    help\n",
      "helps ------>>>    help\n",
      "helpful ------>>>    help\n",
      "helped ------>>>    help\n",
      "finally ------>>>    final\n",
      "final ------>>>    final\n"
     ]
    }
   ],
   "source": [
    "for w in words:\n",
    "    print(f\"{w} ------>>>    {s.stem(w)}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "657ba40c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47740319",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06be1961",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b6674a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "442dbd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "words=['generous','generation','generously','generate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1cd3027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generous ------>>>    gener\n",
      "generation ------>>>    gener\n",
      "generously ------>>>    gener\n",
      "generate ------>>>    gener\n"
     ]
    }
   ],
   "source": [
    "for w in words:\n",
    "    print(f\"{w} ------>>>    {p.stem(w)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dae1b40d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generous ------>>>    generous\n",
      "generation ------>>>    generat\n",
      "generously ------>>>    generous\n",
      "generate ------>>>    generat\n"
     ]
    }
   ],
   "source": [
    "for w in words:\n",
    "    print(f\"{w} ------>>>    {s.stem(w)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3cdf10",
   "metadata": {},
   "source": [
    "**So we can infer here that SnowballStemmer works better than PorterStemmer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e32a8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b084460",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a6d29186",
   "metadata": {},
   "source": [
    "# <font color='blue'> Lemmanization</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11d9071",
   "metadata": {},
   "source": [
    "**Lemmatization is the process of grouping together the different inflected forms of a word so they can be analyzed as a single item. Lemmatization is similar to stemming but it brings context to the words. So it links words with similar meanings to one word.** "
   ]
  },
  {
   "cell_type": "raw",
   "id": "1a3db46d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb1df676",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf717c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp=spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6652481f",
   "metadata": {},
   "outputs": [],
   "source": [
    "s=u'I have been studying for the past 5 years as I am a teacher and my hobby has always been to study'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "14f09aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "d=nlp(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "513c422f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I \t PRON \t I\n",
      "have \t AUX \t have\n",
      "been \t AUX \t be\n",
      "studying \t VERB \t study\n",
      "for \t ADP \t for\n",
      "the \t DET \t the\n",
      "past \t ADJ \t past\n",
      "5 \t NUM \t 5\n",
      "years \t NOUN \t year\n",
      "as \t SCONJ \t as\n",
      "I \t PRON \t I\n",
      "am \t AUX \t be\n",
      "a \t DET \t a\n",
      "teacher \t NOUN \t teacher\n",
      "and \t CCONJ \t and\n",
      "my \t PRON \t my\n",
      "hobby \t NOUN \t hobby\n",
      "has \t AUX \t have\n",
      "always \t ADV \t always\n",
      "been \t AUX \t be\n",
      "to \t PART \t to\n",
      "study \t VERB \t study\n"
     ]
    }
   ],
   "source": [
    "for token in d:\n",
    "    print(token.text,\"\\t\",token.pos_,\"\\t\",token.lemma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85648899",
   "metadata": {},
   "source": [
    "Studying has been converted to study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b23754",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

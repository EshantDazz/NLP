{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "853ebdf0",
   "metadata": {},
   "source": [
    "# <div class='alert alert-info'><font color='black'>New Word Prediction</font></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "349e9bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9e4664",
   "metadata": {},
   "source": [
    "### Getting the file with which we will work on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "90a74463",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readfile(d):\n",
    "    with open(d) as f:\n",
    "        s=f.read()\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f4d6fade",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=readfile('Novel.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5c74317f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1198622"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f713bb22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "71940e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHAPTER 1\n",
      "\n",
      "Loomings.\n",
      "\n",
      "\n",
      "Call me Ishmael.  Some years ago--never mind how long\n",
      "precisely--having little or no money in my purse, and nothing\n",
      "particular to interest me on shore, I thought I would sail about a\n",
      "little and see the watery part of the world.  It is a way I have of\n",
      "driving off the spleen and regulating the circulation.  Whenever I\n",
      "find myself growing grim about the mouth; whenever it is a damp,\n",
      "drizzly November in my soul; whenever I find myself involuntarily\n",
      "pausing before coffin warehouses, and bringing up the rear of every\n",
      "funeral I meet; and especially whenever my hypos get such an upper\n",
      "hand of me, that it requires a strong moral principle to prevent me\n",
      "from deliberately stepping into the street, and methodically knocking\n",
      "people's hats off--then, I account it high time to get to sea as soon\n",
      "as I can.  This is my substitute for pistol and ball.  With a\n",
      "philosophical flourish Cato throws himself upon his sword; I quietly\n",
      "take to the ship.  There is nothing surprising in this.  If they but\n",
      "knew it, almost all men in their degree, some time or other, cherish\n",
      "very nearly the same feelings towards the ocean with me.\n",
      "\n",
      "There now is your insular city of the Manhattoes, belted round by\n",
      "wharves as Indian isles by coral reefs--commerce surrounds it with\n",
      "her surf.  Right and left, the streets take you waterward.  Its\n",
      "extreme downtown is the battery, where that noble mole is washed by\n",
      "waves, and cooled by breezes, which a few hours previous were out of\n",
      "sight of land.  Look at the crowds of water-gazers there.\n",
      "\n",
      "Circumambulate the city of a dreamy Sabbath afternoon.  Go from\n",
      "Corlears Hook to Coenties Slip, and from thence, by Whitehall,\n",
      "northward.  What do you see?--Posted like silent sentinels all around\n",
      "the town, stand thousands upon thousands of mortal men fixed in ocean\n",
      "reveries.  Some leaning against the spiles; some seated upon the\n",
      "pier-heads; some looking over the bulwarks of ships from China; some\n",
      "high aloft in the rigging, as if striving to get a still better\n",
      "seaward peep.  But these are all landsmen; of week days pent up in\n",
      "lath and plaster--tied to counters, nailed to benches, clinched to\n",
      "desks.  How then is this?  Are the green fields gone?  What do they\n",
      "here?\n",
      "\n",
      "But look! here come more crowds, pacing straight for the water, and\n",
      "seemingly bound for a dive.  Strange!  Nothing will content them but\n",
      "the extremest limit of the land; loitering under the shady lee of\n",
      "yonder warehouses will not suffice.  No.  They must get just as nigh\n",
      "the water as they possibly can without falling in.  And there they\n",
      "stand--miles of them--leagues.  Inlanders all, they come from lanes\n",
      "and alleys, streets and avenues--north, east, south, and west.  Yet\n",
      "here they all unite.  Tell me, does the magnetic virtue of the\n",
      "needles of the compasses of all those ships attract them thither?\n",
      "\n",
      "Once more.  Say you are in the country; in some high land of lakes.\n",
      "Take almost any path you please, and ten to one it carries you down\n",
      "in a dale, and leaves you there by a pool in the stream.  There is\n",
      "magic in it.  Let the most absent-minded of men be plunged in his\n",
      "deepest reveries--stand that man on his legs, set his feet a-going,\n",
      "and he will infallibly lead you to water, if water there be in all\n",
      "that region.  Should you ever be athirst in the great American\n",
      "desert, try this experiment, if your caravan happen to be supplied\n",
      "with a metaphysical professor.  Yes, as every one knows, meditation\n",
      "and water are wedded for ever.\n",
      "\n",
      "But here is an artist.  He desires to paint you the dreamiest,\n",
      "shadiest, quietest, most enchanting bit of romantic landscape in all\n",
      "the valley of the Saco.  What is the chief element he employs?  There\n",
      "stand his trees, each with a hollow trunk, as if a hermit and a\n",
      "crucifix were within; and here sleeps his meadow, and there sleep his\n",
      "cattle; and up from yonder cottage goes a sleepy smoke.  Deep into\n",
      "distant woodlands winds a mazy way, reaching to overlapping spurs of\n",
      "mountains bathed in their hill-side blue.  But though the picture\n",
      "lies thus tranced, and though this pine-tree shakes down its sighs\n",
      "like leaves upon this shepherd's head, yet all were vain, unless the\n",
      "shepherd's eye were fixed upon the magic stream before him.  Go visit\n",
      "the Prairies in June, when for scores on scores of miles you wade\n",
      "knee-deep among Tiger-lilies--what is the one charm\n",
      "wanting?--Water--there is not a drop of water there!  Were Niagara\n",
      "but a cataract of sand, would you travel your thousand miles to see\n",
      "it?  Why did the poor poet of Tennessee, upon suddenly receiving two\n",
      "handfuls of silver, deliberate whether to buy him a coat, which he\n",
      "sadly needed, or invest his money in a pedestrian trip to Rockaway\n",
      "Beach?  Why is almost every robust healthy boy with a robust healthy\n",
      "soul in him, at some time or other crazy to go to sea?  Why upon your\n",
      "first voyage as a passenger, did you yourself feel such a mystical\n",
      "vibration, when first told that you and your ship were now out of\n",
      "sight of land?  Why did the old Persians hold the sea holy?  Why did\n",
      "the Greeks \n"
     ]
    }
   ],
   "source": [
    "print(a[:5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8712a46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "267bd2a0",
   "metadata": {},
   "source": [
    "**Since we want our code to process faster lets do it using only 5000 words**<br>\n",
    "You can try from your own end to work with the whole corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f338ce36",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=a[:5000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7114a18b",
   "metadata": {},
   "source": [
    "## <font color='blue'> Tokenize and clean text</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db2e585",
   "metadata": {},
   "source": [
    "**Since we are not gonna do any Parsing or Named Entity Recognition task in future we can disable those for faster computation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9999fc1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76735b99",
   "metadata": {},
   "source": [
    "**Since we are not gonna do any Parsing or Named Entity Recognition task in future we can disable those for faster computation**}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb8d7f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a49b5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm',disable=['parser', 'tagger','ner'])\n",
    "nlp.max_length = 1198623\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "897fea8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_punc(d):\n",
    "    return [token.text.lower() for token in nlp(d) if token.text not in '\\n\\n \\n\\n\\n!\"-#$%&()--.*+,-/:;<=>?@[\\\\]^_`{|}~\\t\\n ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac3d752",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e91e6645",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n"
     ]
    }
   ],
   "source": [
    "tokens=separate_punc(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcbe0c1",
   "metadata": {},
   "source": [
    "**So we have removed all the kinds of different punctuations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e0a4ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chapter', '1', 'loomings', 'call', 'me', 'ishmael', 'some', 'years', 'ago', 'never', 'mind', 'how', 'long', 'precisely', 'having', 'little', 'or', 'no', 'money', 'in', 'my', 'purse', 'and', 'nothing', 'particular', 'to', 'interest', 'me', 'on', 'shore', 'i', 'thought', 'i', 'would', 'sail', 'about', 'a', 'little', 'and', 'see', 'the', 'watery', 'part', 'of', 'the', 'world', 'it', 'is', 'a', 'way', 'i', 'have', 'of', 'driving', 'off', 'the', 'spleen', 'and', 'regulating', 'the', 'circulation', 'whenever', 'i', 'find', 'myself', 'growing', 'grim', 'about', 'the', 'mouth', 'whenever', 'it', 'is', 'a', 'damp', 'drizzly', 'november', 'in', 'my', 'soul', 'whenever', 'i', 'find', 'myself', 'involuntarily', 'pausing', 'before', 'coffin', 'warehouses', 'and', 'bringing', 'up', 'the', 'rear', 'of', 'every', 'funeral', 'i', 'meet', 'and', 'especially', 'whenever', 'my', 'hypos', 'get', 'such', 'an', 'upper', 'hand', 'of', 'me', 'that', 'it', 'requires', 'a', 'strong', 'moral', 'principle', 'to', 'prevent', 'me', 'from', 'deliberately', 'stepping', 'into', 'the', 'street', 'and', 'methodically', 'knocking', 'people', \"'s\", 'hats', 'off', 'then', 'i', 'account', 'it', 'high', 'time', 'to', 'get', 'to', 'sea', 'as', 'soon', 'as', 'i', 'can', 'this', 'is', 'my', 'substitute', 'for', 'pistol', 'and', 'ball', 'with', 'a', 'philosophical', 'flourish', 'cato', 'throws', 'himself', 'upon', 'his', 'sword', 'i', 'quietly', 'take', 'to', 'the', 'ship', 'there', 'is', 'nothing', 'surprising', 'in', 'this', 'if', 'they', 'but', 'knew', 'it', 'almost', 'all', 'men', 'in', 'their', 'degree', 'some', 'time', 'or', 'other', 'cherish', 'very', 'nearly', 'the', 'same', 'feelings', 'towards', 'the', 'ocean', 'with', 'me', 'there', 'now', 'is', 'your', 'insular', 'city', 'of', 'the', 'manhattoes', 'belted', 'round', 'by', 'wharves', 'as', 'indian', 'isles', 'by', 'coral', 'reefs', 'commerce', 'surrounds', 'it', 'with', 'her', 'surf', 'right', 'and', 'left', 'the', 'streets', 'take', 'you', 'waterward', 'its', 'extreme', 'downtown', 'is', 'the', 'battery', 'where', 'that', 'noble', 'mole', 'is', 'washed', 'by', 'waves', 'and', 'cooled', 'by', 'breezes', 'which', 'a', 'few', 'hours', 'previous', 'were', 'out', 'of', 'sight', 'of', 'land', 'look', 'at', 'the', 'crowds', 'of', 'water', 'gazers', 'there', 'circumambulate', 'the', 'city', 'of', 'a', 'dreamy', 'sabbath', 'afternoon', 'go', 'from', 'corlears', 'hook', 'to', 'coenties', 'slip', 'and', 'from', 'thence', 'by', 'whitehall', 'northward', 'what', 'do', 'you', 'see?--posted', 'like', 'silent', 'sentinels', 'all', 'around', 'the', 'town', 'stand', 'thousands', 'upon', 'thousands', 'of', 'mortal', 'men', 'fixed', 'in', 'ocean', 'reveries', 'some', 'leaning', 'against', 'the', 'spiles', 'some', 'seated', 'upon', 'the', 'pier', 'heads', 'some', 'looking', 'over', 'the', 'bulwarks', 'of', 'ships', 'from', 'china', 'some', 'high', 'aloft', 'in', 'the', 'rigging', 'as', 'if', 'striving', 'to', 'get', 'a', 'still', 'better', 'seaward', 'peep', 'but', 'these', 'are', 'all', 'landsmen', 'of', 'week', 'days', 'pent', 'up', 'in', 'lath', 'and', 'plaster', 'tied', 'to', 'counters', 'nailed', 'to', 'benches', 'clinched', 'to', 'desks', 'how', 'then', 'is', 'this', 'are', 'the', 'green', 'fields', 'gone', 'what', 'do', 'they', 'here', 'but', 'look', 'here', 'come', 'more', 'crowds', 'pacing', 'straight', 'for', 'the', 'water', 'and', 'seemingly', 'bound', 'for', 'a', 'dive', 'strange', 'nothing', 'will', 'content', 'them', 'but', 'the', 'extremest', 'limit', 'of', 'the', 'land', 'loitering', 'under', 'the', 'shady', 'lee', 'of', 'yonder', 'warehouses', 'will', 'not', 'suffice', 'no', 'they', 'must', 'get', 'just', 'as', 'nigh', 'the', 'water', 'as', 'they', 'possibly', 'can', 'without', 'falling', 'in', 'and', 'there', 'they', 'stand', 'miles', 'of', 'them', 'leagues', 'inlanders', 'all', 'they', 'come', 'from', 'lanes', 'and', 'alleys', 'streets', 'and', 'avenues', 'north', 'east', 'south', 'and', 'west', 'yet', 'here', 'they', 'all', 'unite', 'tell', 'me', 'does', 'the', 'magnetic', 'virtue', 'of', 'the', 'needles', 'of', 'the', 'compasses', 'of', 'all', 'those', 'ships', 'attract', 'them', 'thither', 'once', 'more', 'say', 'you', 'are', 'in', 'the', 'country', 'in', 'some', 'high', 'land', 'of', 'lakes', 'take', 'almost', 'any', 'path', 'you', 'please', 'and', 'ten', 'to', 'one', 'it', 'carries', 'you', 'down', 'in', 'a', 'dale', 'and', 'leaves', 'you', 'there', 'by', 'a', 'pool', 'in', 'the', 'stream', 'there', 'is', 'magic', 'in', 'it', 'let', 'the', 'most', 'absent', 'minded', 'of', 'men', 'be', 'plunged', 'in', 'his', 'deepest', 'reveries', 'stand', 'that', 'man', 'on', 'his', 'legs', 'set', 'his', 'feet', 'a', 'going', 'and', 'he', 'will', 'infallibly', 'lead', 'you', 'to', 'water', 'if', 'water', 'there', 'be', 'in', 'all', 'that', 'region', 'should', 'you', 'ever', 'be', 'athirst', 'in', 'the', 'great', 'american', 'desert', 'try', 'this', 'experiment', 'if', 'your', 'caravan', 'happen', 'to', 'be', 'supplied', 'with', 'a', 'metaphysical', 'professor', 'yes', 'as', 'every', 'one', 'knows', 'meditation', 'and', 'water', 'are', 'wedded', 'for', 'ever', 'but', 'here', 'is', 'an', 'artist', 'he', 'desires', 'to', 'paint', 'you', 'the', 'dreamiest', 'shadiest', 'quietest', 'most', 'enchanting', 'bit', 'of', 'romantic', 'landscape', 'in', 'all', 'the', 'valley', 'of', 'the', 'saco', 'what', 'is', 'the', 'chief', 'element', 'he', 'employs', 'there', 'stand', 'his', 'trees', 'each', 'with', 'a', 'hollow', 'trunk', 'as', 'if', 'a', 'hermit', 'and', 'a', 'crucifix', 'were', 'within', 'and', 'here', 'sleeps', 'his', 'meadow', 'and', 'there', 'sleep', 'his', 'cattle', 'and', 'up', 'from', 'yonder', 'cottage', 'goes', 'a', 'sleepy', 'smoke', 'deep', 'into', 'distant', 'woodlands', 'winds', 'a', 'mazy', 'way', 'reaching', 'to', 'overlapping', 'spurs', 'of', 'mountains', 'bathed', 'in', 'their', 'hill', 'side', 'blue', 'but', 'though', 'the', 'picture', 'lies', 'thus', 'tranced', 'and', 'though', 'this', 'pine', 'tree', 'shakes', 'down', 'its', 'sighs', 'like', 'leaves', 'upon', 'this', 'shepherd', \"'s\", 'head', 'yet', 'all', 'were', 'vain', 'unless', 'the', 'shepherd', \"'s\", 'eye', 'were', 'fixed', 'upon', 'the', 'magic', 'stream', 'before', 'him', 'go', 'visit', 'the', 'prairies', 'in', 'june', 'when', 'for', 'scores', 'on', 'scores', 'of', 'miles', 'you', 'wade', 'knee', 'deep', 'among', 'tiger', 'lilies', 'what', 'is', 'the', 'one', 'charm', 'wanting?--water', 'there', 'is', 'not', 'a', 'drop', 'of', 'water', 'there', 'were', 'niagara', 'but', 'a', 'cataract', 'of', 'sand', 'would', 'you', 'travel', 'your', 'thousand', 'miles', 'to', 'see', 'it', 'why', 'did', 'the', 'poor', 'poet', 'of', 'tennessee', 'upon', 'suddenly', 'receiving', 'two', 'handfuls', 'of', 'silver', 'deliberate', 'whether', 'to', 'buy', 'him', 'a', 'coat', 'which', 'he', 'sadly', 'needed', 'or', 'invest', 'his', 'money', 'in', 'a', 'pedestrian', 'trip', 'to', 'rockaway', 'beach', 'why', 'is', 'almost', 'every', 'robust', 'healthy', 'boy', 'with', 'a', 'robust', 'healthy', 'soul', 'in', 'him', 'at', 'some', 'time', 'or', 'other', 'crazy', 'to', 'go', 'to', 'sea', 'why', 'upon', 'your', 'first', 'voyage', 'as', 'a', 'passenger', 'did', 'you', 'yourself', 'feel', 'such', 'a', 'mystical', 'vibration', 'when', 'first', 'told', 'that', 'you', 'and', 'your', 'ship', 'were', 'now', 'out', 'of', 'sight', 'of', 'land', 'why', 'did', 'the', 'old', 'persians', 'hold', 'the', 'sea', 'holy', 'why', 'did', 'the', 'greeks']\n"
     ]
    }
   ],
   "source": [
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "738ccab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "901"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f32793",
   "metadata": {},
   "source": [
    "## <font color='blue'> Now we will create sequence of tokens</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25f7902",
   "metadata": {},
   "source": [
    "**We are gonna now give 10 words and make our neural network predict the 11th word**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b9e14bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train= 10+1 \n",
    "text_sequence = []\n",
    "for i in range(train, len(tokens)):\n",
    "    seq = tokens[i-train:i]  \n",
    "    text_sequence.append(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83a8de00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(text_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9bbbfa03",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chapter',\n",
       " '1',\n",
       " 'loomings',\n",
       " 'call',\n",
       " 'me',\n",
       " 'ishmael',\n",
       " 'some',\n",
       " 'years',\n",
       " 'ago',\n",
       " 'never',\n",
       " 'mind']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_sequence[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd0354f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " 'loomings',\n",
       " 'call',\n",
       " 'me',\n",
       " 'ishmael',\n",
       " 'some',\n",
       " 'years',\n",
       " 'ago',\n",
       " 'never',\n",
       " 'mind',\n",
       " 'how']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_sequence[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc42ee35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "890"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len((text_sequence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b19b568c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chapter 1 loomings call me ishmael some years ago never mind'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(text_sequence[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "947c717d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1 loomings call me ishmael some years ago never mind how'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(text_sequence[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74c84f0",
   "metadata": {},
   "source": [
    "- So we are getting the 10 training words including our target word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d62acfe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "['chapter', '1', 'loomings', 'call', 'me', 'ishmael', 'some', 'years', 'ago', 'never', 'mind']\n"
     ]
    }
   ],
   "source": [
    "print(len(text_sequence[0]))\n",
    "print(text_sequence[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a168ae",
   "metadata": {},
   "source": [
    "- So we can see there are eleven words\n",
    "- These are the list of first 11 words from our data\n",
    "- 10 initial words and the last 11th word which we will be targetting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390f9375",
   "metadata": {},
   "source": [
    "## <font color='blue'>Keras Tokenization</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c3a0fff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "57a61428",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok= Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aab098b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok.fit_on_texts(text_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fb71e522",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sequences=tok.texts_to_sequences(text_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac327109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[454, 453, 452, 450, 25, 449, 15, 446, 444, 443, 118]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cb270741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[453, 452, 450, 25, 449, 15, 446, 444, 443, 118, 60]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_sequences[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a434228e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "[454, 453, 452, 450, 25, 449, 15, 446, 444, 443, 118]\n"
     ]
    }
   ],
   "source": [
    "print(len(new_sequences[0]))\n",
    "print(new_sequences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "caed3fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'the', 2: 'of', 3: 'and', 4: 'a', 5: 'in', 6: 'to', 7: 'is', 8: 'you', 9: 'there', 10: 'i', 11: 'it', 12: 'as', 13: 'all', 14: 'his', 15: 'some', 16: 'upon', 17: 'they', 18: 'but', 19: 'water', 20: 'from', 21: 'this', 22: 'with', 23: 'by', 24: 'were', 25: 'me', 26: 'that', 27: 'for', 28: 'if', 29: 'your', 30: 'here', 31: 'why', 32: 'or', 33: 'my', 34: 'whenever', 35: 'get', 36: 'land', 37: 'what', 38: 'stand', 39: 'are', 40: 'be', 41: 'he', 42: 'did', 43: 'nothing', 44: 'on', 45: 'up', 46: 'every', 47: \"'s\", 48: 'high', 49: 'time', 50: 'take', 51: 'almost', 52: 'men', 53: 'go', 54: 'will', 55: 'them', 56: 'miles', 57: 'one', 58: 'him', 59: 'sea', 60: 'how', 61: 'little', 62: 'no', 63: 'money', 64: 'would', 65: 'about', 66: 'see', 67: 'way', 68: 'off', 69: 'find', 70: 'myself', 71: 'soul', 72: 'before', 73: 'warehouses', 74: 'such', 75: 'an', 76: 'into', 77: 'then', 78: 'can', 79: 'ship', 80: 'their', 81: 'other', 82: 'ocean', 83: 'now', 84: 'city', 85: 'streets', 86: 'its', 87: 'which', 88: 'out', 89: 'sight', 90: 'look', 91: 'at', 92: 'crowds', 93: 'do', 94: 'like', 95: 'thousands', 96: 'fixed', 97: 'reveries', 98: 'ships', 99: 'come', 100: 'more', 101: 'yonder', 102: 'not', 103: 'yet', 104: 'down', 105: 'leaves', 106: 'stream', 107: 'magic', 108: 'most', 109: 'ever', 110: 'deep', 111: 'though', 112: 'shepherd', 113: 'when', 114: 'scores', 115: 'robust', 116: 'healthy', 117: 'first', 118: 'mind', 119: 'long', 120: 'precisely', 121: 'having', 122: 'purse', 123: 'particular', 124: 'interest', 125: 'shore', 126: 'thought', 127: 'sail', 128: 'watery', 129: 'part', 130: 'world', 131: 'have', 132: 'driving', 133: 'spleen', 134: 'regulating', 135: 'circulation', 136: 'growing', 137: 'grim', 138: 'mouth', 139: 'damp', 140: 'drizzly', 141: 'november', 142: 'involuntarily', 143: 'pausing', 144: 'coffin', 145: 'bringing', 146: 'rear', 147: 'funeral', 148: 'meet', 149: 'especially', 150: 'hypos', 151: 'upper', 152: 'hand', 153: 'requires', 154: 'strong', 155: 'moral', 156: 'principle', 157: 'prevent', 158: 'deliberately', 159: 'stepping', 160: 'street', 161: 'methodically', 162: 'knocking', 163: 'people', 164: 'hats', 165: 'account', 166: 'soon', 167: 'substitute', 168: 'pistol', 169: 'ball', 170: 'philosophical', 171: 'flourish', 172: 'cato', 173: 'throws', 174: 'himself', 175: 'sword', 176: 'quietly', 177: 'surprising', 178: 'knew', 179: 'degree', 180: 'cherish', 181: 'very', 182: 'nearly', 183: 'same', 184: 'feelings', 185: 'towards', 186: 'insular', 187: 'manhattoes', 188: 'belted', 189: 'round', 190: 'wharves', 191: 'indian', 192: 'isles', 193: 'coral', 194: 'reefs', 195: 'commerce', 196: 'surrounds', 197: 'her', 198: 'surf', 199: 'right', 200: 'left', 201: 'waterward', 202: 'extreme', 203: 'downtown', 204: 'battery', 205: 'where', 206: 'noble', 207: 'mole', 208: 'washed', 209: 'waves', 210: 'cooled', 211: 'breezes', 212: 'few', 213: 'hours', 214: 'previous', 215: 'gazers', 216: 'circumambulate', 217: 'dreamy', 218: 'sabbath', 219: 'afternoon', 220: 'corlears', 221: 'hook', 222: 'coenties', 223: 'slip', 224: 'thence', 225: 'whitehall', 226: 'northward', 227: 'see?--posted', 228: 'silent', 229: 'sentinels', 230: 'around', 231: 'town', 232: 'mortal', 233: 'leaning', 234: 'against', 235: 'spiles', 236: 'seated', 237: 'pier', 238: 'heads', 239: 'looking', 240: 'over', 241: 'bulwarks', 242: 'china', 243: 'aloft', 244: 'rigging', 245: 'striving', 246: 'still', 247: 'better', 248: 'seaward', 249: 'peep', 250: 'these', 251: 'landsmen', 252: 'week', 253: 'days', 254: 'pent', 255: 'lath', 256: 'plaster', 257: 'tied', 258: 'counters', 259: 'nailed', 260: 'benches', 261: 'clinched', 262: 'desks', 263: 'green', 264: 'fields', 265: 'gone', 266: 'pacing', 267: 'straight', 268: 'seemingly', 269: 'bound', 270: 'dive', 271: 'strange', 272: 'content', 273: 'extremest', 274: 'limit', 275: 'loitering', 276: 'under', 277: 'shady', 278: 'lee', 279: 'suffice', 280: 'must', 281: 'just', 282: 'nigh', 283: 'possibly', 284: 'without', 285: 'falling', 286: 'leagues', 287: 'inlanders', 288: 'lanes', 289: 'alleys', 290: 'avenues', 291: 'north', 292: 'east', 293: 'south', 294: 'west', 295: 'unite', 296: 'tell', 297: 'does', 298: 'magnetic', 299: 'virtue', 300: 'needles', 301: 'compasses', 302: 'those', 303: 'attract', 304: 'thither', 305: 'once', 306: 'say', 307: 'country', 308: 'lakes', 309: 'any', 310: 'path', 311: 'please', 312: 'ten', 313: 'carries', 314: 'dale', 315: 'pool', 316: 'let', 317: 'absent', 318: 'minded', 319: 'plunged', 320: 'deepest', 321: 'man', 322: 'legs', 323: 'set', 324: 'feet', 325: 'going', 326: 'infallibly', 327: 'lead', 328: 'region', 329: 'should', 330: 'athirst', 331: 'great', 332: 'american', 333: 'desert', 334: 'try', 335: 'experiment', 336: 'caravan', 337: 'happen', 338: 'supplied', 339: 'metaphysical', 340: 'professor', 341: 'yes', 342: 'knows', 343: 'meditation', 344: 'wedded', 345: 'artist', 346: 'desires', 347: 'paint', 348: 'dreamiest', 349: 'shadiest', 350: 'quietest', 351: 'enchanting', 352: 'bit', 353: 'romantic', 354: 'landscape', 355: 'valley', 356: 'saco', 357: 'chief', 358: 'element', 359: 'employs', 360: 'trees', 361: 'each', 362: 'hollow', 363: 'trunk', 364: 'hermit', 365: 'crucifix', 366: 'within', 367: 'sleeps', 368: 'meadow', 369: 'sleep', 370: 'cattle', 371: 'cottage', 372: 'goes', 373: 'sleepy', 374: 'smoke', 375: 'distant', 376: 'woodlands', 377: 'winds', 378: 'mazy', 379: 'reaching', 380: 'overlapping', 381: 'spurs', 382: 'mountains', 383: 'bathed', 384: 'hill', 385: 'side', 386: 'blue', 387: 'picture', 388: 'lies', 389: 'thus', 390: 'tranced', 391: 'pine', 392: 'tree', 393: 'shakes', 394: 'sighs', 395: 'head', 396: 'vain', 397: 'unless', 398: 'eye', 399: 'visit', 400: 'prairies', 401: 'june', 402: 'wade', 403: 'knee', 404: 'among', 405: 'tiger', 406: 'lilies', 407: 'charm', 408: 'wanting?--water', 409: 'drop', 410: 'niagara', 411: 'cataract', 412: 'sand', 413: 'travel', 414: 'thousand', 415: 'poor', 416: 'poet', 417: 'tennessee', 418: 'suddenly', 419: 'receiving', 420: 'two', 421: 'handfuls', 422: 'silver', 423: 'deliberate', 424: 'whether', 425: 'buy', 426: 'coat', 427: 'sadly', 428: 'needed', 429: 'invest', 430: 'pedestrian', 431: 'trip', 432: 'rockaway', 433: 'beach', 434: 'boy', 435: 'crazy', 436: 'voyage', 437: 'passenger', 438: 'yourself', 439: 'feel', 440: 'mystical', 441: 'vibration', 442: 'told', 443: 'never', 444: 'ago', 445: 'old', 446: 'years', 447: 'persians', 448: 'hold', 449: 'ishmael', 450: 'call', 451: 'holy', 452: 'loomings', 453: '1', 454: 'chapter'}\n"
     ]
    }
   ],
   "source": [
    "print(tok.index_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6724fbcf",
   "metadata": {},
   "source": [
    "**tokenizer.index_word will help us to get the word after we pass the index**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da52d8d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a5d1fa2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer.index_word[:10]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "47a97fd5",
   "metadata": {},
   "source": [
    "**The above statement won't work since this is a dict and not a list**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb30da42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ba699d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ---> the\n",
      "2 ---> of\n",
      "3 ---> and\n",
      "4 ---> a\n",
      "5 ---> in\n",
      "6 ---> to\n",
      "7 ---> is\n",
      "8 ---> you\n",
      "9 ---> there\n",
      "10 ---> i\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for a in tok.index_word:\n",
    "    print(a,\"--->\",tok.index_word[a])\n",
    "    i+=1\n",
    "    if i==10 : break "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766336a5",
   "metadata": {},
   "source": [
    "**These are the numbers which have been encoded to the words shown above**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b550cded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "454 : chapter\n",
      "453 : 1\n",
      "452 : loomings\n",
      "450 : call\n",
      "25 : me\n",
      "449 : ishmael\n",
      "15 : some\n",
      "446 : years\n",
      "444 : ago\n",
      "443 : never\n",
      "118 : mind\n"
     ]
    }
   ],
   "source": [
    "for i in new_sequences[0]:\n",
    "    print(f'{i} : {tok.index_word[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97dfacf",
   "metadata": {},
   "source": [
    "**These are words with their indexes for the first sentence**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "45189867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('chapter', 1),\n",
       "             ('1', 2),\n",
       "             ('loomings', 3),\n",
       "             ('call', 4),\n",
       "             ('me', 60),\n",
       "             ('ishmael', 6),\n",
       "             ('some', 84),\n",
       "             ('years', 8),\n",
       "             ('ago', 9),\n",
       "             ('never', 10),\n",
       "             ('mind', 11),\n",
       "             ('how', 22),\n",
       "             ('long', 11),\n",
       "             ('precisely', 11),\n",
       "             ('having', 11),\n",
       "             ('little', 22),\n",
       "             ('or', 44),\n",
       "             ('no', 22),\n",
       "             ('money', 22),\n",
       "             ('in', 231),\n",
       "             ('my', 44),\n",
       "             ('purse', 11),\n",
       "             ('and', 286),\n",
       "             ('nothing', 33),\n",
       "             ('particular', 11),\n",
       "             ('to', 220),\n",
       "             ('interest', 11),\n",
       "             ('on', 33),\n",
       "             ('shore', 11),\n",
       "             ('i', 99),\n",
       "             ('thought', 11),\n",
       "             ('would', 22),\n",
       "             ('sail', 11),\n",
       "             ('about', 22),\n",
       "             ('a', 275),\n",
       "             ('see', 22),\n",
       "             ('the', 490),\n",
       "             ('watery', 11),\n",
       "             ('part', 11),\n",
       "             ('of', 330),\n",
       "             ('world', 11),\n",
       "             ('it', 99),\n",
       "             ('is', 154),\n",
       "             ('way', 22),\n",
       "             ('have', 11),\n",
       "             ('driving', 11),\n",
       "             ('off', 22),\n",
       "             ('spleen', 11),\n",
       "             ('regulating', 11),\n",
       "             ('circulation', 11),\n",
       "             ('whenever', 44),\n",
       "             ('find', 22),\n",
       "             ('myself', 22),\n",
       "             ('growing', 11),\n",
       "             ('grim', 11),\n",
       "             ('mouth', 11),\n",
       "             ('damp', 11),\n",
       "             ('drizzly', 11),\n",
       "             ('november', 11),\n",
       "             ('soul', 22),\n",
       "             ('involuntarily', 11),\n",
       "             ('pausing', 11),\n",
       "             ('before', 22),\n",
       "             ('coffin', 11),\n",
       "             ('warehouses', 22),\n",
       "             ('bringing', 11),\n",
       "             ('up', 33),\n",
       "             ('rear', 11),\n",
       "             ('every', 33),\n",
       "             ('funeral', 11),\n",
       "             ('meet', 11),\n",
       "             ('especially', 11),\n",
       "             ('hypos', 11),\n",
       "             ('get', 44),\n",
       "             ('such', 22),\n",
       "             ('an', 22),\n",
       "             ('upper', 11),\n",
       "             ('hand', 11),\n",
       "             ('that', 55),\n",
       "             ('requires', 11),\n",
       "             ('strong', 11),\n",
       "             ('moral', 11),\n",
       "             ('principle', 11),\n",
       "             ('prevent', 11),\n",
       "             ('from', 66),\n",
       "             ('deliberately', 11),\n",
       "             ('stepping', 11),\n",
       "             ('into', 22),\n",
       "             ('street', 11),\n",
       "             ('methodically', 11),\n",
       "             ('knocking', 11),\n",
       "             ('people', 11),\n",
       "             (\"'s\", 33),\n",
       "             ('hats', 11),\n",
       "             ('then', 22),\n",
       "             ('account', 11),\n",
       "             ('high', 33),\n",
       "             ('time', 33),\n",
       "             ('sea', 27),\n",
       "             ('as', 99),\n",
       "             ('soon', 11),\n",
       "             ('can', 22),\n",
       "             ('this', 66),\n",
       "             ('substitute', 11),\n",
       "             ('for', 55),\n",
       "             ('pistol', 11),\n",
       "             ('ball', 11),\n",
       "             ('with', 66),\n",
       "             ('philosophical', 11),\n",
       "             ('flourish', 11),\n",
       "             ('cato', 11),\n",
       "             ('throws', 11),\n",
       "             ('himself', 11),\n",
       "             ('upon', 77),\n",
       "             ('his', 88),\n",
       "             ('sword', 11),\n",
       "             ('quietly', 11),\n",
       "             ('take', 33),\n",
       "             ('ship', 22),\n",
       "             ('there', 121),\n",
       "             ('surprising', 11),\n",
       "             ('if', 55),\n",
       "             ('they', 77),\n",
       "             ('but', 77),\n",
       "             ('knew', 11),\n",
       "             ('almost', 33),\n",
       "             ('all', 99),\n",
       "             ('men', 33),\n",
       "             ('their', 22),\n",
       "             ('degree', 11),\n",
       "             ('other', 22),\n",
       "             ('cherish', 11),\n",
       "             ('very', 11),\n",
       "             ('nearly', 11),\n",
       "             ('same', 11),\n",
       "             ('feelings', 11),\n",
       "             ('towards', 11),\n",
       "             ('ocean', 22),\n",
       "             ('now', 22),\n",
       "             ('your', 55),\n",
       "             ('insular', 11),\n",
       "             ('city', 22),\n",
       "             ('manhattoes', 11),\n",
       "             ('belted', 11),\n",
       "             ('round', 11),\n",
       "             ('by', 66),\n",
       "             ('wharves', 11),\n",
       "             ('indian', 11),\n",
       "             ('isles', 11),\n",
       "             ('coral', 11),\n",
       "             ('reefs', 11),\n",
       "             ('commerce', 11),\n",
       "             ('surrounds', 11),\n",
       "             ('her', 11),\n",
       "             ('surf', 11),\n",
       "             ('right', 11),\n",
       "             ('left', 11),\n",
       "             ('streets', 22),\n",
       "             ('you', 143),\n",
       "             ('waterward', 11),\n",
       "             ('its', 22),\n",
       "             ('extreme', 11),\n",
       "             ('downtown', 11),\n",
       "             ('battery', 11),\n",
       "             ('where', 11),\n",
       "             ('noble', 11),\n",
       "             ('mole', 11),\n",
       "             ('washed', 11),\n",
       "             ('waves', 11),\n",
       "             ('cooled', 11),\n",
       "             ('breezes', 11),\n",
       "             ('which', 22),\n",
       "             ('few', 11),\n",
       "             ('hours', 11),\n",
       "             ('previous', 11),\n",
       "             ('were', 66),\n",
       "             ('out', 22),\n",
       "             ('sight', 22),\n",
       "             ('land', 44),\n",
       "             ('look', 22),\n",
       "             ('at', 22),\n",
       "             ('crowds', 22),\n",
       "             ('water', 77),\n",
       "             ('gazers', 11),\n",
       "             ('circumambulate', 11),\n",
       "             ('dreamy', 11),\n",
       "             ('sabbath', 11),\n",
       "             ('afternoon', 11),\n",
       "             ('go', 33),\n",
       "             ('corlears', 11),\n",
       "             ('hook', 11),\n",
       "             ('coenties', 11),\n",
       "             ('slip', 11),\n",
       "             ('thence', 11),\n",
       "             ('whitehall', 11),\n",
       "             ('northward', 11),\n",
       "             ('what', 44),\n",
       "             ('do', 22),\n",
       "             ('see?--posted', 11),\n",
       "             ('like', 22),\n",
       "             ('silent', 11),\n",
       "             ('sentinels', 11),\n",
       "             ('around', 11),\n",
       "             ('town', 11),\n",
       "             ('stand', 44),\n",
       "             ('thousands', 22),\n",
       "             ('mortal', 11),\n",
       "             ('fixed', 22),\n",
       "             ('reveries', 22),\n",
       "             ('leaning', 11),\n",
       "             ('against', 11),\n",
       "             ('spiles', 11),\n",
       "             ('seated', 11),\n",
       "             ('pier', 11),\n",
       "             ('heads', 11),\n",
       "             ('looking', 11),\n",
       "             ('over', 11),\n",
       "             ('bulwarks', 11),\n",
       "             ('ships', 22),\n",
       "             ('china', 11),\n",
       "             ('aloft', 11),\n",
       "             ('rigging', 11),\n",
       "             ('striving', 11),\n",
       "             ('still', 11),\n",
       "             ('better', 11),\n",
       "             ('seaward', 11),\n",
       "             ('peep', 11),\n",
       "             ('these', 11),\n",
       "             ('are', 44),\n",
       "             ('landsmen', 11),\n",
       "             ('week', 11),\n",
       "             ('days', 11),\n",
       "             ('pent', 11),\n",
       "             ('lath', 11),\n",
       "             ('plaster', 11),\n",
       "             ('tied', 11),\n",
       "             ('counters', 11),\n",
       "             ('nailed', 11),\n",
       "             ('benches', 11),\n",
       "             ('clinched', 11),\n",
       "             ('desks', 11),\n",
       "             ('green', 11),\n",
       "             ('fields', 11),\n",
       "             ('gone', 11),\n",
       "             ('here', 55),\n",
       "             ('come', 22),\n",
       "             ('more', 22),\n",
       "             ('pacing', 11),\n",
       "             ('straight', 11),\n",
       "             ('seemingly', 11),\n",
       "             ('bound', 11),\n",
       "             ('dive', 11),\n",
       "             ('strange', 11),\n",
       "             ('will', 33),\n",
       "             ('content', 11),\n",
       "             ('them', 33),\n",
       "             ('extremest', 11),\n",
       "             ('limit', 11),\n",
       "             ('loitering', 11),\n",
       "             ('under', 11),\n",
       "             ('shady', 11),\n",
       "             ('lee', 11),\n",
       "             ('yonder', 22),\n",
       "             ('not', 22),\n",
       "             ('suffice', 11),\n",
       "             ('must', 11),\n",
       "             ('just', 11),\n",
       "             ('nigh', 11),\n",
       "             ('possibly', 11),\n",
       "             ('without', 11),\n",
       "             ('falling', 11),\n",
       "             ('miles', 33),\n",
       "             ('leagues', 11),\n",
       "             ('inlanders', 11),\n",
       "             ('lanes', 11),\n",
       "             ('alleys', 11),\n",
       "             ('avenues', 11),\n",
       "             ('north', 11),\n",
       "             ('east', 11),\n",
       "             ('south', 11),\n",
       "             ('west', 11),\n",
       "             ('yet', 22),\n",
       "             ('unite', 11),\n",
       "             ('tell', 11),\n",
       "             ('does', 11),\n",
       "             ('magnetic', 11),\n",
       "             ('virtue', 11),\n",
       "             ('needles', 11),\n",
       "             ('compasses', 11),\n",
       "             ('those', 11),\n",
       "             ('attract', 11),\n",
       "             ('thither', 11),\n",
       "             ('once', 11),\n",
       "             ('say', 11),\n",
       "             ('country', 11),\n",
       "             ('lakes', 11),\n",
       "             ('any', 11),\n",
       "             ('path', 11),\n",
       "             ('please', 11),\n",
       "             ('ten', 11),\n",
       "             ('one', 33),\n",
       "             ('carries', 11),\n",
       "             ('down', 22),\n",
       "             ('dale', 11),\n",
       "             ('leaves', 22),\n",
       "             ('pool', 11),\n",
       "             ('stream', 22),\n",
       "             ('magic', 22),\n",
       "             ('let', 11),\n",
       "             ('most', 22),\n",
       "             ('absent', 11),\n",
       "             ('minded', 11),\n",
       "             ('be', 44),\n",
       "             ('plunged', 11),\n",
       "             ('deepest', 11),\n",
       "             ('man', 11),\n",
       "             ('legs', 11),\n",
       "             ('set', 11),\n",
       "             ('feet', 11),\n",
       "             ('going', 11),\n",
       "             ('he', 44),\n",
       "             ('infallibly', 11),\n",
       "             ('lead', 11),\n",
       "             ('region', 11),\n",
       "             ('should', 11),\n",
       "             ('ever', 22),\n",
       "             ('athirst', 11),\n",
       "             ('great', 11),\n",
       "             ('american', 11),\n",
       "             ('desert', 11),\n",
       "             ('try', 11),\n",
       "             ('experiment', 11),\n",
       "             ('caravan', 11),\n",
       "             ('happen', 11),\n",
       "             ('supplied', 11),\n",
       "             ('metaphysical', 11),\n",
       "             ('professor', 11),\n",
       "             ('yes', 11),\n",
       "             ('knows', 11),\n",
       "             ('meditation', 11),\n",
       "             ('wedded', 11),\n",
       "             ('artist', 11),\n",
       "             ('desires', 11),\n",
       "             ('paint', 11),\n",
       "             ('dreamiest', 11),\n",
       "             ('shadiest', 11),\n",
       "             ('quietest', 11),\n",
       "             ('enchanting', 11),\n",
       "             ('bit', 11),\n",
       "             ('romantic', 11),\n",
       "             ('landscape', 11),\n",
       "             ('valley', 11),\n",
       "             ('saco', 11),\n",
       "             ('chief', 11),\n",
       "             ('element', 11),\n",
       "             ('employs', 11),\n",
       "             ('trees', 11),\n",
       "             ('each', 11),\n",
       "             ('hollow', 11),\n",
       "             ('trunk', 11),\n",
       "             ('hermit', 11),\n",
       "             ('crucifix', 11),\n",
       "             ('within', 11),\n",
       "             ('sleeps', 11),\n",
       "             ('meadow', 11),\n",
       "             ('sleep', 11),\n",
       "             ('cattle', 11),\n",
       "             ('cottage', 11),\n",
       "             ('goes', 11),\n",
       "             ('sleepy', 11),\n",
       "             ('smoke', 11),\n",
       "             ('deep', 22),\n",
       "             ('distant', 11),\n",
       "             ('woodlands', 11),\n",
       "             ('winds', 11),\n",
       "             ('mazy', 11),\n",
       "             ('reaching', 11),\n",
       "             ('overlapping', 11),\n",
       "             ('spurs', 11),\n",
       "             ('mountains', 11),\n",
       "             ('bathed', 11),\n",
       "             ('hill', 11),\n",
       "             ('side', 11),\n",
       "             ('blue', 11),\n",
       "             ('though', 22),\n",
       "             ('picture', 11),\n",
       "             ('lies', 11),\n",
       "             ('thus', 11),\n",
       "             ('tranced', 11),\n",
       "             ('pine', 11),\n",
       "             ('tree', 11),\n",
       "             ('shakes', 11),\n",
       "             ('sighs', 11),\n",
       "             ('shepherd', 22),\n",
       "             ('head', 11),\n",
       "             ('vain', 11),\n",
       "             ('unless', 11),\n",
       "             ('eye', 11),\n",
       "             ('him', 33),\n",
       "             ('visit', 11),\n",
       "             ('prairies', 11),\n",
       "             ('june', 11),\n",
       "             ('when', 22),\n",
       "             ('scores', 22),\n",
       "             ('wade', 11),\n",
       "             ('knee', 11),\n",
       "             ('among', 11),\n",
       "             ('tiger', 11),\n",
       "             ('lilies', 11),\n",
       "             ('charm', 11),\n",
       "             ('wanting?--water', 11),\n",
       "             ('drop', 11),\n",
       "             ('niagara', 11),\n",
       "             ('cataract', 11),\n",
       "             ('sand', 11),\n",
       "             ('travel', 11),\n",
       "             ('thousand', 11),\n",
       "             ('why', 47),\n",
       "             ('did', 35),\n",
       "             ('poor', 11),\n",
       "             ('poet', 11),\n",
       "             ('tennessee', 11),\n",
       "             ('suddenly', 11),\n",
       "             ('receiving', 11),\n",
       "             ('two', 11),\n",
       "             ('handfuls', 11),\n",
       "             ('silver', 11),\n",
       "             ('deliberate', 11),\n",
       "             ('whether', 11),\n",
       "             ('buy', 11),\n",
       "             ('coat', 11),\n",
       "             ('sadly', 11),\n",
       "             ('needed', 11),\n",
       "             ('invest', 11),\n",
       "             ('pedestrian', 11),\n",
       "             ('trip', 11),\n",
       "             ('rockaway', 11),\n",
       "             ('beach', 11),\n",
       "             ('robust', 22),\n",
       "             ('healthy', 22),\n",
       "             ('boy', 11),\n",
       "             ('crazy', 11),\n",
       "             ('first', 22),\n",
       "             ('voyage', 11),\n",
       "             ('passenger', 11),\n",
       "             ('yourself', 11),\n",
       "             ('feel', 11),\n",
       "             ('mystical', 11),\n",
       "             ('vibration', 11),\n",
       "             ('told', 11),\n",
       "             ('old', 9),\n",
       "             ('persians', 8),\n",
       "             ('hold', 7),\n",
       "             ('holy', 4)])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok.word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f448e90f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('chapter', 1)\n",
      "('1', 2)\n",
      "('loomings', 3)\n",
      "('call', 4)\n",
      "('me', 60)\n",
      "('ishmael', 6)\n",
      "('some', 84)\n",
      "('years', 8)\n",
      "('ago', 9)\n",
      "('never', 10)\n",
      "('mind', 11)\n",
      "('how', 22)\n",
      "('long', 11)\n",
      "('precisely', 11)\n",
      "('having', 11)\n",
      "('little', 22)\n",
      "('or', 44)\n",
      "('no', 22)\n",
      "('money', 22)\n",
      "('in', 231)\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for a in tok.word_counts:\n",
    "    print((a,tok.word_counts[a]))\n",
    "    i+=1\n",
    "    if i==20 : break "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0d89b7",
   "metadata": {},
   "source": [
    "**It is telling us which word is occuring how many times**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5ccb87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "32918deb",
   "metadata": {},
   "source": [
    "**Let's check the number of unique words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "80742e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "size=len(tok.word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a23c2f0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "454"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54963c9b",
   "metadata": {},
   "source": [
    "## <font color='blue'> Now lets convert them into numpy array</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a4713cb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(new_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "19c190d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "00accc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences=np.array(new_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ce53b44e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[454, 453, 452, ..., 444, 443, 118],\n",
       "       [453, 452, 450, ..., 443, 118,  60],\n",
       "       [452, 450,  25, ..., 118,  60, 119],\n",
       "       ...,\n",
       "       [ 36,  31,  42, ...,  59, 451,  31],\n",
       "       [ 31,  42,   1, ..., 451,  31,  42],\n",
       "       [ 42,   1, 445, ...,  31,  42,   1]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3afbc7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5474c481",
   "metadata": {},
   "source": [
    "## <font color='blue'> Train Test Split</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf08a0ce",
   "metadata": {},
   "source": [
    "So lets see how we decide X and Y value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067c0ba1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a6fef0b3",
   "metadata": {},
   "source": [
    "X will be the the featrues whereas Y will be the label so for X we need extract all except the last column<br>\n",
    "and for Y we have to extract all the rows and only the first columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b8a0744d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=sequences[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "98eea64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=sequences[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133c4081",
   "metadata": {},
   "source": [
    "So we have extracted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4611f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "96df6623",
   "metadata": {},
   "source": [
    "**Lets convert the y value to categorical**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "101a047b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c40c20dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(890,)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1b4f9c86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "454"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1ab145e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=to_categorical(y,num_classes=size+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1019a1dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(890, 455)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "608c0ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len=x.shape[1]  #It will be 10 bcoz we earlier decided we are gonna take 10 words and decide the 11th word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0dfeb87e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "15f9db57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_len"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cdfe33",
   "metadata": {},
   "source": [
    "## <div class='alert alert-info'> Creating LSTM model</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4ff36c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,LSTM,Embedding #Embedding we are using to deal with the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f5ee4bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(vocab_size, seq_len):\n",
    "    model=Sequential()\n",
    "    model.add(Embedding(vocab_size,seq_len,input_length=seq_len))\n",
    "    model.add(LSTM(150,return_sequences=True))  #seq_len*15=150\n",
    "    model.add(LSTM(150))\n",
    "    model.add(Dense(150,activation='relu'))\n",
    "    model.add(Dense(vocab_size,activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad858b1d",
   "metadata": {},
   "source": [
    "## <font color='blue'>Training the model</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "359fb376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 10, 10)            4550      \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 10, 150)           96600     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 150)               180600    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 150)               22650     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 455)               68705     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 373,105\n",
      "Trainable params: 373,105\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=create_model(size+1,seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c2209d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5656b575",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import dump,load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ac3ad4",
   "metadata": {},
   "source": [
    "## <font color='blue'>Fitting the model</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ce079ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/850\n",
      "2/2 [==============================] - 3s 93ms/step - loss: 6.1199 - accuracy: 0.0191\n",
      "Epoch 2/850\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 6.1169 - accuracy: 0.0517\n",
      "Epoch 3/850\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 6.1122 - accuracy: 0.0517\n",
      "Epoch 4/850\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 6.1036 - accuracy: 0.0517\n",
      "Epoch 5/850\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 6.0867 - accuracy: 0.0517\n",
      "Epoch 6/850\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 6.0487 - accuracy: 0.0517\n",
      "Epoch 7/850\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 5.9671 - accuracy: 0.0517\n",
      "Epoch 8/850\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 5.8131 - accuracy: 0.0517\n",
      "Epoch 9/850\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 5.6611 - accuracy: 0.0517\n",
      "Epoch 10/850\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 5.6924 - accuracy: 0.0517\n",
      "Epoch 11/850\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 5.6124 - accuracy: 0.0517\n",
      "Epoch 12/850\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 5.5595 - accuracy: 0.0517\n",
      "Epoch 13/850\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 5.5619 - accuracy: 0.0517\n",
      "Epoch 14/850\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 5.5575 - accuracy: 0.0337\n",
      "Epoch 15/850\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 5.5427 - accuracy: 0.0337\n",
      "Epoch 16/850\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 5.5340 - accuracy: 0.0337\n",
      "Epoch 17/850\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 5.5343 - accuracy: 0.0337\n",
      "Epoch 18/850\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 5.5273 - accuracy: 0.0337\n",
      "Epoch 19/850\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 5.5162 - accuracy: 0.0517\n",
      "Epoch 20/850\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 5.5110 - accuracy: 0.0517\n",
      "Epoch 21/850\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 5.5108 - accuracy: 0.0517\n",
      "Epoch 22/850\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 5.5077 - accuracy: 0.0517\n",
      "Epoch 23/850\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 5.5031 - accuracy: 0.0517\n",
      "Epoch 24/850\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 5.4964 - accuracy: 0.0517\n",
      "Epoch 25/850\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 5.4901 - accuracy: 0.0517\n",
      "Epoch 26/850\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 5.4803 - accuracy: 0.0517\n",
      "Epoch 27/850\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 5.4674 - accuracy: 0.0517\n",
      "Epoch 28/850\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 5.4537 - accuracy: 0.0517\n",
      "Epoch 29/850\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 5.4365 - accuracy: 0.0517\n",
      "Epoch 30/850\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 5.4185 - accuracy: 0.0517\n",
      "Epoch 31/850\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 5.4013 - accuracy: 0.0517\n",
      "Epoch 32/850\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 5.3848 - accuracy: 0.0517\n",
      "Epoch 33/850\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 5.3685 - accuracy: 0.0528\n",
      "Epoch 34/850\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 5.3481 - accuracy: 0.0528\n",
      "Epoch 35/850\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 5.3208 - accuracy: 0.0528\n",
      "Epoch 36/850\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 5.2916 - accuracy: 0.0528\n",
      "Epoch 37/850\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 5.2581 - accuracy: 0.0528\n",
      "Epoch 38/850\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 5.2210 - accuracy: 0.0539\n",
      "Epoch 39/850\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 5.1759 - accuracy: 0.0539\n",
      "Epoch 40/850\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 5.1335 - accuracy: 0.0528\n",
      "Epoch 41/850\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 5.0953 - accuracy: 0.0539\n",
      "Epoch 42/850\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 5.0669 - accuracy: 0.0539\n",
      "Epoch 43/850\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 5.0349 - accuracy: 0.0539\n",
      "Epoch 44/850\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 5.0098 - accuracy: 0.0539\n",
      "Epoch 45/850\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 4.9885 - accuracy: 0.0551\n",
      "Epoch 46/850\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 4.9649 - accuracy: 0.0539\n",
      "Epoch 47/850\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 4.9502 - accuracy: 0.0517\n",
      "Epoch 48/850\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 4.9309 - accuracy: 0.0539\n",
      "Epoch 49/850\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 4.9233 - accuracy: 0.0539\n",
      "Epoch 50/850\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 4.9196 - accuracy: 0.0528\n",
      "Epoch 51/850\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 4.9040 - accuracy: 0.0517\n",
      "Epoch 52/850\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 4.8840 - accuracy: 0.0517\n",
      "Epoch 53/850\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 4.8703 - accuracy: 0.0528\n",
      "Epoch 54/850\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 4.8662 - accuracy: 0.0562\n",
      "Epoch 55/850\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 4.8583 - accuracy: 0.0573\n",
      "Epoch 56/850\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 4.8388 - accuracy: 0.0584\n",
      "Epoch 57/850\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 4.8271 - accuracy: 0.0573\n",
      "Epoch 58/850\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 4.8177 - accuracy: 0.0562\n",
      "Epoch 59/850\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 4.8085 - accuracy: 0.0551\n",
      "Epoch 60/850\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 4.7898 - accuracy: 0.0573\n",
      "Epoch 61/850\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 4.7787 - accuracy: 0.0562\n",
      "Epoch 62/850\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 4.7665 - accuracy: 0.0573\n",
      "Epoch 63/850\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 4.7519 - accuracy: 0.0618\n",
      "Epoch 64/850\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 4.7349 - accuracy: 0.0652\n",
      "Epoch 65/850\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 4.7195 - accuracy: 0.0663\n",
      "Epoch 66/850\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 4.7063 - accuracy: 0.0629\n",
      "Epoch 67/850\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 4.6921 - accuracy: 0.0640\n",
      "Epoch 68/850\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 4.6755 - accuracy: 0.0764\n",
      "Epoch 69/850\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 4.6593 - accuracy: 0.0775\n",
      "Epoch 70/850\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 4.6449 - accuracy: 0.0730\n",
      "Epoch 71/850\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 4.6292 - accuracy: 0.0775\n",
      "Epoch 72/850\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 4.6115 - accuracy: 0.0787\n",
      "Epoch 73/850\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 4.5990 - accuracy: 0.0708\n",
      "Epoch 74/850\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 4.5768 - accuracy: 0.0820\n",
      "Epoch 75/850\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 4.5620 - accuracy: 0.0775\n",
      "Epoch 76/850\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 4.5411 - accuracy: 0.0854\n",
      "Epoch 77/850\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 4.5178 - accuracy: 0.0843\n",
      "Epoch 78/850\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 4.4952 - accuracy: 0.0854\n",
      "Epoch 79/850\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 4.4783 - accuracy: 0.0843\n",
      "Epoch 80/850\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 4.4582 - accuracy: 0.0899\n",
      "Epoch 81/850\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 4.4422 - accuracy: 0.0933\n",
      "Epoch 82/850\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 4.4188 - accuracy: 0.0944\n",
      "Epoch 83/850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 98ms/step - loss: 4.3895 - accuracy: 0.0955\n",
      "Epoch 84/850\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 4.3576 - accuracy: 0.0978\n",
      "Epoch 85/850\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 4.3299 - accuracy: 0.1011\n",
      "Epoch 86/850\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 4.3135 - accuracy: 0.1022\n",
      "Epoch 87/850\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 4.2924 - accuracy: 0.0989\n",
      "Epoch 88/850\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 4.2487 - accuracy: 0.1056\n",
      "Epoch 89/850\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 4.2343 - accuracy: 0.0978\n",
      "Epoch 90/850\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 4.2057 - accuracy: 0.1056\n",
      "Epoch 91/850\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 4.1802 - accuracy: 0.0978\n",
      "Epoch 92/850\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 4.1503 - accuracy: 0.1180\n",
      "Epoch 93/850\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 4.1160 - accuracy: 0.1213\n",
      "Epoch 94/850\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 4.0931 - accuracy: 0.1146\n",
      "Epoch 95/850\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 4.0688 - accuracy: 0.1213\n",
      "Epoch 96/850\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 4.0356 - accuracy: 0.1258\n",
      "Epoch 97/850\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 4.0328 - accuracy: 0.1169\n",
      "Epoch 98/850\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 3.9910 - accuracy: 0.1270\n",
      "Epoch 99/850\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 3.9710 - accuracy: 0.1270\n",
      "Epoch 100/850\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 3.9490 - accuracy: 0.1315\n",
      "Epoch 101/850\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 3.9242 - accuracy: 0.1360\n",
      "Epoch 102/850\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 3.9016 - accuracy: 0.1382\n",
      "Epoch 103/850\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 3.8943 - accuracy: 0.1348\n",
      "Epoch 104/850\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 3.8638 - accuracy: 0.1404\n",
      "Epoch 105/850\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 3.8391 - accuracy: 0.1416\n",
      "Epoch 106/850\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 3.8293 - accuracy: 0.1404\n",
      "Epoch 107/850\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 3.8159 - accuracy: 0.1438\n",
      "Epoch 108/850\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 3.7847 - accuracy: 0.1438\n",
      "Epoch 109/850\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 3.7599 - accuracy: 0.1506\n",
      "Epoch 110/850\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 3.7392 - accuracy: 0.1528\n",
      "Epoch 111/850\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 3.7259 - accuracy: 0.1528\n",
      "Epoch 112/850\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 3.7369 - accuracy: 0.1483\n",
      "Epoch 113/850\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 3.7395 - accuracy: 0.1506\n",
      "Epoch 114/850\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 3.7418 - accuracy: 0.1438\n",
      "Epoch 115/850\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 3.7237 - accuracy: 0.1371\n",
      "Epoch 116/850\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 3.7185 - accuracy: 0.1360\n",
      "Epoch 117/850\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 3.7226 - accuracy: 0.1438\n",
      "Epoch 118/850\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 3.7536 - accuracy: 0.1348\n",
      "Epoch 119/850\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 3.7206 - accuracy: 0.1382\n",
      "Epoch 120/850\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 3.6855 - accuracy: 0.1371\n",
      "Epoch 121/850\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 3.6237 - accuracy: 0.1573\n",
      "Epoch 122/850\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 3.5864 - accuracy: 0.1483\n",
      "Epoch 123/850\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 3.5885 - accuracy: 0.1539\n",
      "Epoch 124/850\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 3.5692 - accuracy: 0.1483\n",
      "Epoch 125/850\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 3.5853 - accuracy: 0.1528\n",
      "Epoch 126/850\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 3.5732 - accuracy: 0.1539\n",
      "Epoch 127/850\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 3.5336 - accuracy: 0.1551\n",
      "Epoch 128/850\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 3.4902 - accuracy: 0.1618\n",
      "Epoch 129/850\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 3.4741 - accuracy: 0.1674\n",
      "Epoch 130/850\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 3.4923 - accuracy: 0.1652\n",
      "Epoch 131/850\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 3.4642 - accuracy: 0.1652\n",
      "Epoch 132/850\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 3.4199 - accuracy: 0.1719\n",
      "Epoch 133/850\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 3.3820 - accuracy: 0.1809\n",
      "Epoch 134/850\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 3.3829 - accuracy: 0.1809\n",
      "Epoch 135/850\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 3.3657 - accuracy: 0.1775\n",
      "Epoch 136/850\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 3.3454 - accuracy: 0.1843\n",
      "Epoch 137/850\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 3.3173 - accuracy: 0.1876\n",
      "Epoch 138/850\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 3.2984 - accuracy: 0.1933\n",
      "Epoch 139/850\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 3.2845 - accuracy: 0.1888\n",
      "Epoch 140/850\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 3.2682 - accuracy: 0.1966\n",
      "Epoch 141/850\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 3.2497 - accuracy: 0.2034\n",
      "Epoch 142/850\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 3.2269 - accuracy: 0.2124\n",
      "Epoch 143/850\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 3.2126 - accuracy: 0.2124\n",
      "Epoch 144/850\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 3.1895 - accuracy: 0.2292\n",
      "Epoch 145/850\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 3.1747 - accuracy: 0.2247\n",
      "Epoch 146/850\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 3.1653 - accuracy: 0.2247\n",
      "Epoch 147/850\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 3.1506 - accuracy: 0.2258\n",
      "Epoch 148/850\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 3.1369 - accuracy: 0.2180\n",
      "Epoch 149/850\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 3.1277 - accuracy: 0.2258\n",
      "Epoch 150/850\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 3.1134 - accuracy: 0.2348\n",
      "Epoch 151/850\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 3.0983 - accuracy: 0.2247\n",
      "Epoch 152/850\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 3.0882 - accuracy: 0.2303\n",
      "Epoch 153/850\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 3.0817 - accuracy: 0.2416\n",
      "Epoch 154/850\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 3.0838 - accuracy: 0.2326\n",
      "Epoch 155/850\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 3.0660 - accuracy: 0.2326\n",
      "Epoch 156/850\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 3.0503 - accuracy: 0.2449\n",
      "Epoch 157/850\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 3.0454 - accuracy: 0.2281\n",
      "Epoch 158/850\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 3.0494 - accuracy: 0.2124\n",
      "Epoch 159/850\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 3.0430 - accuracy: 0.2225\n",
      "Epoch 160/850\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 3.0128 - accuracy: 0.2213\n",
      "Epoch 161/850\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 3.0093 - accuracy: 0.2427\n",
      "Epoch 162/850\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 2.9979 - accuracy: 0.2506\n",
      "Epoch 163/850\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 2.9967 - accuracy: 0.2303\n",
      "Epoch 164/850\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 3.0074 - accuracy: 0.2360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 165/850\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 2.9753 - accuracy: 0.2449\n",
      "Epoch 166/850\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 2.9672 - accuracy: 0.2326\n",
      "Epoch 167/850\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 2.9721 - accuracy: 0.2315\n",
      "Epoch 168/850\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 3.0032 - accuracy: 0.2169\n",
      "Epoch 169/850\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 2.9638 - accuracy: 0.2213\n",
      "Epoch 170/850\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 2.9487 - accuracy: 0.2303\n",
      "Epoch 171/850\n",
      "2/2 [==============================] - 0s 123ms/step - loss: 2.9605 - accuracy: 0.2236\n",
      "Epoch 172/850\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 2.9340 - accuracy: 0.2393\n",
      "Epoch 173/850\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 2.9090 - accuracy: 0.2427\n",
      "Epoch 174/850\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 2.9626 - accuracy: 0.2315\n",
      "Epoch 175/850\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 2.9623 - accuracy: 0.2348\n",
      "Epoch 176/850\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 2.9713 - accuracy: 0.2213\n",
      "Epoch 177/850\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 2.9492 - accuracy: 0.2326\n",
      "Epoch 178/850\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 2.9287 - accuracy: 0.2281\n",
      "Epoch 179/850\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 2.9343 - accuracy: 0.2292\n",
      "Epoch 180/850\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 2.9440 - accuracy: 0.2124\n",
      "Epoch 181/850\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 2.9831 - accuracy: 0.2056\n",
      "Epoch 182/850\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 2.9840 - accuracy: 0.2090\n",
      "Epoch 183/850\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 2.9385 - accuracy: 0.2236\n",
      "Epoch 184/850\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 2.9338 - accuracy: 0.2225\n",
      "Epoch 185/850\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 2.9592 - accuracy: 0.2315\n",
      "Epoch 186/850\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 2.9708 - accuracy: 0.2303\n",
      "Epoch 187/850\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 2.9769 - accuracy: 0.2315\n",
      "Epoch 188/850\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 2.9040 - accuracy: 0.2213\n",
      "Epoch 189/850\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 2.8866 - accuracy: 0.2236\n",
      "Epoch 190/850\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 2.8862 - accuracy: 0.2427\n",
      "Epoch 191/850\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 2.7943 - accuracy: 0.2787\n",
      "Epoch 192/850\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 2.7984 - accuracy: 0.2640\n",
      "Epoch 193/850\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 2.8149 - accuracy: 0.2562\n",
      "Epoch 194/850\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 2.8095 - accuracy: 0.2562\n",
      "Epoch 195/850\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 2.7894 - accuracy: 0.2685\n",
      "Epoch 196/850\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 2.8034 - accuracy: 0.2719\n",
      "Epoch 197/850\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 2.8011 - accuracy: 0.2865\n",
      "Epoch 198/850\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 2.7499 - accuracy: 0.2764\n",
      "Epoch 199/850\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 2.7256 - accuracy: 0.2910\n",
      "Epoch 200/850\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 2.6906 - accuracy: 0.3090\n",
      "Epoch 201/850\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 2.6918 - accuracy: 0.3022\n",
      "Epoch 202/850\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 2.6771 - accuracy: 0.3067\n",
      "Epoch 203/850\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 2.6708 - accuracy: 0.2921\n",
      "Epoch 204/850\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 2.6681 - accuracy: 0.3022\n",
      "Epoch 205/850\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 2.6675 - accuracy: 0.2910\n",
      "Epoch 206/850\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 2.6454 - accuracy: 0.3067\n",
      "Epoch 207/850\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 2.6328 - accuracy: 0.3315\n",
      "Epoch 208/850\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 2.6297 - accuracy: 0.3225\n",
      "Epoch 209/850\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 2.6168 - accuracy: 0.3404\n",
      "Epoch 210/850\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 2.5951 - accuracy: 0.3438\n",
      "Epoch 211/850\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 2.5750 - accuracy: 0.3573\n",
      "Epoch 212/850\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 2.5644 - accuracy: 0.3551\n",
      "Epoch 213/850\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 2.5522 - accuracy: 0.3573\n",
      "Epoch 214/850\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 2.5452 - accuracy: 0.3539\n",
      "Epoch 215/850\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 2.5350 - accuracy: 0.3596\n",
      "Epoch 216/850\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 2.5253 - accuracy: 0.3708\n",
      "Epoch 217/850\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 2.5180 - accuracy: 0.3697\n",
      "Epoch 218/850\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 2.5016 - accuracy: 0.3764\n",
      "Epoch 219/850\n",
      "2/2 [==============================] - 0s 124ms/step - loss: 2.4984 - accuracy: 0.3730\n",
      "Epoch 220/850\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 2.4924 - accuracy: 0.3764\n",
      "Epoch 221/850\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 2.4820 - accuracy: 0.3899\n",
      "Epoch 222/850\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 2.4796 - accuracy: 0.3775\n",
      "Epoch 223/850\n",
      "2/2 [==============================] - 0s 122ms/step - loss: 2.4925 - accuracy: 0.3640\n",
      "Epoch 224/850\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 2.4934 - accuracy: 0.3584\n",
      "Epoch 225/850\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 2.5010 - accuracy: 0.3596\n",
      "Epoch 226/850\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 2.4982 - accuracy: 0.3596\n",
      "Epoch 227/850\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 2.4869 - accuracy: 0.3573\n",
      "Epoch 228/850\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 2.4835 - accuracy: 0.3551\n",
      "Epoch 229/850\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 2.4612 - accuracy: 0.3562\n",
      "Epoch 230/850\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 2.4549 - accuracy: 0.3697\n",
      "Epoch 231/850\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 2.4530 - accuracy: 0.3674\n",
      "Epoch 232/850\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 2.4404 - accuracy: 0.3742\n",
      "Epoch 233/850\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 2.4304 - accuracy: 0.3753\n",
      "Epoch 234/850\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 2.4178 - accuracy: 0.3910\n",
      "Epoch 235/850\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 2.4015 - accuracy: 0.3966\n",
      "Epoch 236/850\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 2.3977 - accuracy: 0.4034\n",
      "Epoch 237/850\n",
      "2/2 [==============================] - 0s 122ms/step - loss: 2.3931 - accuracy: 0.4011\n",
      "Epoch 238/850\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 2.3850 - accuracy: 0.3955\n",
      "Epoch 239/850\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 2.3677 - accuracy: 0.4022\n",
      "Epoch 240/850\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 2.3618 - accuracy: 0.4079\n",
      "Epoch 241/850\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 2.3532 - accuracy: 0.4067\n",
      "Epoch 242/850\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 2.3405 - accuracy: 0.4067\n",
      "Epoch 243/850\n",
      "2/2 [==============================] - 0s 123ms/step - loss: 2.3475 - accuracy: 0.4146\n",
      "Epoch 244/850\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 2.3390 - accuracy: 0.4191\n",
      "Epoch 245/850\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 2.3401 - accuracy: 0.4225\n",
      "Epoch 246/850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 94ms/step - loss: 2.3354 - accuracy: 0.4202\n",
      "Epoch 247/850\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 2.3373 - accuracy: 0.4157\n",
      "Epoch 248/850\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 2.3319 - accuracy: 0.4112\n",
      "Epoch 249/850\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 2.3241 - accuracy: 0.4011\n",
      "Epoch 250/850\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 2.3322 - accuracy: 0.4022\n",
      "Epoch 251/850\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 2.3192 - accuracy: 0.4079\n",
      "Epoch 252/850\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 2.3057 - accuracy: 0.3989\n",
      "Epoch 253/850\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 2.2926 - accuracy: 0.4011\n",
      "Epoch 254/850\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 2.3024 - accuracy: 0.3843\n",
      "Epoch 255/850\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 2.3138 - accuracy: 0.3888\n",
      "Epoch 256/850\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 2.3151 - accuracy: 0.3944\n",
      "Epoch 257/850\n",
      "2/2 [==============================] - 0s 122ms/step - loss: 2.3168 - accuracy: 0.4034\n",
      "Epoch 258/850\n",
      "2/2 [==============================] - 0s 123ms/step - loss: 2.3115 - accuracy: 0.3921\n",
      "Epoch 259/850\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 2.3338 - accuracy: 0.4067\n",
      "Epoch 260/850\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 2.3143 - accuracy: 0.3989\n",
      "Epoch 261/850\n",
      "2/2 [==============================] - 0s 123ms/step - loss: 2.3069 - accuracy: 0.4067\n",
      "Epoch 262/850\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 2.3064 - accuracy: 0.4045\n",
      "Epoch 263/850\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 2.2855 - accuracy: 0.4067\n",
      "Epoch 264/850\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 2.2687 - accuracy: 0.4000\n",
      "Epoch 265/850\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 2.2811 - accuracy: 0.3820\n",
      "Epoch 266/850\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 2.2598 - accuracy: 0.4022\n",
      "Epoch 267/850\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 2.2474 - accuracy: 0.3955\n",
      "Epoch 268/850\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 2.2269 - accuracy: 0.4315\n",
      "Epoch 269/850\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 2.2279 - accuracy: 0.4180\n",
      "Epoch 270/850\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 2.2201 - accuracy: 0.4247\n",
      "Epoch 271/850\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 2.2267 - accuracy: 0.4169\n",
      "Epoch 272/850\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 2.2639 - accuracy: 0.3955\n",
      "Epoch 273/850\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 2.2372 - accuracy: 0.4067\n",
      "Epoch 274/850\n",
      "2/2 [==============================] - 0s 157ms/step - loss: 2.2569 - accuracy: 0.4157\n",
      "Epoch 275/850\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 2.2807 - accuracy: 0.3921\n",
      "Epoch 276/850\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 2.2812 - accuracy: 0.4034\n",
      "Epoch 277/850\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 2.2888 - accuracy: 0.3876\n",
      "Epoch 278/850\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 2.2440 - accuracy: 0.3955\n",
      "Epoch 279/850\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 2.2330 - accuracy: 0.4056\n",
      "Epoch 280/850\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 2.2326 - accuracy: 0.4247\n",
      "Epoch 281/850\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 2.2174 - accuracy: 0.4416\n",
      "Epoch 282/850\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 2.2002 - accuracy: 0.4270\n",
      "Epoch 283/850\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 2.1832 - accuracy: 0.4169\n",
      "Epoch 284/850\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 2.1845 - accuracy: 0.4067\n",
      "Epoch 285/850\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 2.1890 - accuracy: 0.3955\n",
      "Epoch 286/850\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 2.2023 - accuracy: 0.4079\n",
      "Epoch 287/850\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 2.1816 - accuracy: 0.4112\n",
      "Epoch 288/850\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 2.2187 - accuracy: 0.4034\n",
      "Epoch 289/850\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 2.2248 - accuracy: 0.3888\n",
      "Epoch 290/850\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 2.1631 - accuracy: 0.4247\n",
      "Epoch 291/850\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 2.1932 - accuracy: 0.4067\n",
      "Epoch 292/850\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 2.1725 - accuracy: 0.4157\n",
      "Epoch 293/850\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 2.1739 - accuracy: 0.4056\n",
      "Epoch 294/850\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 2.1985 - accuracy: 0.4101\n",
      "Epoch 295/850\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 2.1878 - accuracy: 0.4202\n",
      "Epoch 296/850\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 2.2056 - accuracy: 0.4124\n",
      "Epoch 297/850\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 2.2242 - accuracy: 0.4135\n",
      "Epoch 298/850\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 2.2489 - accuracy: 0.4079\n",
      "Epoch 299/850\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 2.2816 - accuracy: 0.3843\n",
      "Epoch 300/850\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 2.3014 - accuracy: 0.3708\n",
      "Epoch 301/850\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 2.3032 - accuracy: 0.3629\n",
      "Epoch 302/850\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 2.2720 - accuracy: 0.3461\n",
      "Epoch 303/850\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 2.2817 - accuracy: 0.3337\n",
      "Epoch 304/850\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 2.1870 - accuracy: 0.3944\n",
      "Epoch 305/850\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 2.2029 - accuracy: 0.3831\n",
      "Epoch 306/850\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 2.1343 - accuracy: 0.4101\n",
      "Epoch 307/850\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 2.0870 - accuracy: 0.4416\n",
      "Epoch 308/850\n",
      "2/2 [==============================] - 0s 138ms/step - loss: 2.0716 - accuracy: 0.4461\n",
      "Epoch 309/850\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 2.0404 - accuracy: 0.4843\n",
      "Epoch 310/850\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 2.0243 - accuracy: 0.4787\n",
      "Epoch 311/850\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 2.0242 - accuracy: 0.4685\n",
      "Epoch 312/850\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 2.0336 - accuracy: 0.4719\n",
      "Epoch 313/850\n",
      "2/2 [==============================] - 0s 171ms/step - loss: 2.0261 - accuracy: 0.4809\n",
      "Epoch 314/850\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 1.9926 - accuracy: 0.4921\n",
      "Epoch 315/850\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 1.9844 - accuracy: 0.4978\n",
      "Epoch 316/850\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 1.9759 - accuracy: 0.5079\n",
      "Epoch 317/850\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 1.9595 - accuracy: 0.5225\n",
      "Epoch 318/850\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 1.9417 - accuracy: 0.5393\n",
      "Epoch 319/850\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 1.9316 - accuracy: 0.5449\n",
      "Epoch 320/850\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 1.9200 - accuracy: 0.5461\n",
      "Epoch 321/850\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 1.9141 - accuracy: 0.5404\n",
      "Epoch 322/850\n",
      "2/2 [==============================] - 0s 189ms/step - loss: 1.9021 - accuracy: 0.5449\n",
      "Epoch 323/850\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 1.8917 - accuracy: 0.5449\n",
      "Epoch 324/850\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 1.8839 - accuracy: 0.5472\n",
      "Epoch 325/850\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 1.8750 - accuracy: 0.5596\n",
      "Epoch 326/850\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 1.8678 - accuracy: 0.5584\n",
      "Epoch 327/850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 94ms/step - loss: 1.8715 - accuracy: 0.5562\n",
      "Epoch 328/850\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 1.8698 - accuracy: 0.5483\n",
      "Epoch 329/850\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 1.8672 - accuracy: 0.5573\n",
      "Epoch 330/850\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 1.8674 - accuracy: 0.5483\n",
      "Epoch 331/850\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 1.8606 - accuracy: 0.5494\n",
      "Epoch 332/850\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 1.8605 - accuracy: 0.5494\n",
      "Epoch 333/850\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 1.8534 - accuracy: 0.5573\n",
      "Epoch 334/850\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 1.8572 - accuracy: 0.5551\n",
      "Epoch 335/850\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 1.8481 - accuracy: 0.5517\n",
      "Epoch 336/850\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 1.8598 - accuracy: 0.5573\n",
      "Epoch 337/850\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 1.8537 - accuracy: 0.5539\n",
      "Epoch 338/850\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 1.8630 - accuracy: 0.5416\n",
      "Epoch 339/850\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 1.8525 - accuracy: 0.5371\n",
      "Epoch 340/850\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 1.8591 - accuracy: 0.5438\n",
      "Epoch 341/850\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 1.8821 - accuracy: 0.5382\n",
      "Epoch 342/850\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 1.8729 - accuracy: 0.5416\n",
      "Epoch 343/850\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 1.8696 - accuracy: 0.5326\n",
      "Epoch 344/850\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 1.8854 - accuracy: 0.5292\n",
      "Epoch 345/850\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 1.9148 - accuracy: 0.5112\n",
      "Epoch 346/850\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 1.8838 - accuracy: 0.5348\n",
      "Epoch 347/850\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 1.9285 - accuracy: 0.4876\n",
      "Epoch 348/850\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 1.8980 - accuracy: 0.5090\n",
      "Epoch 349/850\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 1.9214 - accuracy: 0.4978\n",
      "Epoch 350/850\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 1.9482 - accuracy: 0.4809\n",
      "Epoch 351/850\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 1.9862 - accuracy: 0.4472\n",
      "Epoch 352/850\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 2.0053 - accuracy: 0.4337\n",
      "Epoch 353/850\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 2.0190 - accuracy: 0.4303\n",
      "Epoch 354/850\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 2.0230 - accuracy: 0.4180\n",
      "Epoch 355/850\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 1.9858 - accuracy: 0.4213\n",
      "Epoch 356/850\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 1.9642 - accuracy: 0.4348\n",
      "Epoch 357/850\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 1.9401 - accuracy: 0.4562\n",
      "Epoch 358/850\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 1.9406 - accuracy: 0.4360\n",
      "Epoch 359/850\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 1.9302 - accuracy: 0.4607\n",
      "Epoch 360/850\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 1.9099 - accuracy: 0.4674\n",
      "Epoch 361/850\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 1.9060 - accuracy: 0.4697\n",
      "Epoch 362/850\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 1.8576 - accuracy: 0.4910\n",
      "Epoch 363/850\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 1.8375 - accuracy: 0.5034\n",
      "Epoch 364/850\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 1.8686 - accuracy: 0.5011\n",
      "Epoch 365/850\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 1.8968 - accuracy: 0.4640\n",
      "Epoch 366/850\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 1.8864 - accuracy: 0.4787\n",
      "Epoch 367/850\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 1.8351 - accuracy: 0.4910\n",
      "Epoch 368/850\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 1.7941 - accuracy: 0.5326\n",
      "Epoch 369/850\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 1.7679 - accuracy: 0.5584\n",
      "Epoch 370/850\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 1.7736 - accuracy: 0.5506\n",
      "Epoch 371/850\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 1.7800 - accuracy: 0.5225\n",
      "Epoch 372/850\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 1.7668 - accuracy: 0.5270\n",
      "Epoch 373/850\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 1.7300 - accuracy: 0.5708\n",
      "Epoch 374/850\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.7039 - accuracy: 0.5820\n",
      "Epoch 375/850\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 1.7081 - accuracy: 0.5730\n",
      "Epoch 376/850\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 1.7067 - accuracy: 0.5809\n",
      "Epoch 377/850\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 1.7039 - accuracy: 0.5742\n",
      "Epoch 378/850\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 1.6924 - accuracy: 0.5764\n",
      "Epoch 379/850\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.6754 - accuracy: 0.5978\n",
      "Epoch 380/850\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.6817 - accuracy: 0.5944\n",
      "Epoch 381/850\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 1.6964 - accuracy: 0.5955\n",
      "Epoch 382/850\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 1.6884 - accuracy: 0.5809\n",
      "Epoch 383/850\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 1.7003 - accuracy: 0.5910\n",
      "Epoch 384/850\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 1.6908 - accuracy: 0.5775\n",
      "Epoch 385/850\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 1.6938 - accuracy: 0.5798\n",
      "Epoch 386/850\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 1.6874 - accuracy: 0.5865\n",
      "Epoch 387/850\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 1.6976 - accuracy: 0.5798\n",
      "Epoch 388/850\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 1.7082 - accuracy: 0.5764\n",
      "Epoch 389/850\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 1.7127 - accuracy: 0.5742\n",
      "Epoch 390/850\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 1.7089 - accuracy: 0.5742\n",
      "Epoch 391/850\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 1.7094 - accuracy: 0.5674\n",
      "Epoch 392/850\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 1.6975 - accuracy: 0.5753\n",
      "Epoch 393/850\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 1.6998 - accuracy: 0.5865\n",
      "Epoch 394/850\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 1.6717 - accuracy: 0.5854\n",
      "Epoch 395/850\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 1.6663 - accuracy: 0.5787\n",
      "Epoch 396/850\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 1.6511 - accuracy: 0.5944\n",
      "Epoch 397/850\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 1.6394 - accuracy: 0.6090\n",
      "Epoch 398/850\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 1.6233 - accuracy: 0.5933\n",
      "Epoch 399/850\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 1.6148 - accuracy: 0.5989\n",
      "Epoch 400/850\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.6156 - accuracy: 0.6135\n",
      "Epoch 401/850\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 1.6009 - accuracy: 0.6067\n",
      "Epoch 402/850\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.6193 - accuracy: 0.5966\n",
      "Epoch 403/850\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 1.6118 - accuracy: 0.6011\n",
      "Epoch 404/850\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 1.6133 - accuracy: 0.5955\n",
      "Epoch 405/850\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 1.5998 - accuracy: 0.6034\n",
      "Epoch 406/850\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 1.6029 - accuracy: 0.6180\n",
      "Epoch 407/850\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 1.5871 - accuracy: 0.6079\n",
      "Epoch 408/850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 92ms/step - loss: 1.5747 - accuracy: 0.6124\n",
      "Epoch 409/850\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 1.5723 - accuracy: 0.6191\n",
      "Epoch 410/850\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 1.5669 - accuracy: 0.6191\n",
      "Epoch 411/850\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 1.5532 - accuracy: 0.6258\n",
      "Epoch 412/850\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 1.5469 - accuracy: 0.6258\n",
      "Epoch 413/850\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 1.5391 - accuracy: 0.6348\n",
      "Epoch 414/850\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 1.5313 - accuracy: 0.6371\n",
      "Epoch 415/850\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 1.5266 - accuracy: 0.6393\n",
      "Epoch 416/850\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 1.5203 - accuracy: 0.6326\n",
      "Epoch 417/850\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 1.5130 - accuracy: 0.6382\n",
      "Epoch 418/850\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 1.5084 - accuracy: 0.6371\n",
      "Epoch 419/850\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 1.5028 - accuracy: 0.6393\n",
      "Epoch 420/850\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 1.5030 - accuracy: 0.6382\n",
      "Epoch 421/850\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 1.5095 - accuracy: 0.6360\n",
      "Epoch 422/850\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 1.5033 - accuracy: 0.6393\n",
      "Epoch 423/850\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 1.4976 - accuracy: 0.6326\n",
      "Epoch 424/850\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 1.5016 - accuracy: 0.6393\n",
      "Epoch 425/850\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 1.5039 - accuracy: 0.6416\n",
      "Epoch 426/850\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 1.5073 - accuracy: 0.6371\n",
      "Epoch 427/850\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.5087 - accuracy: 0.6281\n",
      "Epoch 428/850\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.5160 - accuracy: 0.6315\n",
      "Epoch 429/850\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 1.5266 - accuracy: 0.6146\n",
      "Epoch 430/850\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 1.5287 - accuracy: 0.6213\n",
      "Epoch 431/850\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 1.5821 - accuracy: 0.6022\n",
      "Epoch 432/850\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.5830 - accuracy: 0.6112\n",
      "Epoch 433/850\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 1.6090 - accuracy: 0.5933\n",
      "Epoch 434/850\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 1.6296 - accuracy: 0.6022\n",
      "Epoch 435/850\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 1.6413 - accuracy: 0.5854\n",
      "Epoch 436/850\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.6830 - accuracy: 0.5573\n",
      "Epoch 437/850\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 1.6909 - accuracy: 0.5303\n",
      "Epoch 438/850\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 1.7242 - accuracy: 0.5011\n",
      "Epoch 439/850\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 1.7927 - accuracy: 0.4809\n",
      "Epoch 440/850\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 1.8229 - accuracy: 0.4798\n",
      "Epoch 441/850\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 1.9479 - accuracy: 0.4213\n",
      "Epoch 442/850\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 2.0266 - accuracy: 0.4101\n",
      "Epoch 443/850\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 1.9587 - accuracy: 0.4169\n",
      "Epoch 444/850\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 1.9887 - accuracy: 0.4157\n",
      "Epoch 445/850\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 1.9446 - accuracy: 0.4449\n",
      "Epoch 446/850\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 1.8769 - accuracy: 0.4360\n",
      "Epoch 447/850\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 1.7687 - accuracy: 0.5101\n",
      "Epoch 448/850\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 1.6970 - accuracy: 0.5315\n",
      "Epoch 449/850\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.7047 - accuracy: 0.5124\n",
      "Epoch 450/850\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.7207 - accuracy: 0.5202\n",
      "Epoch 451/850\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 1.7727 - accuracy: 0.4697\n",
      "Epoch 452/850\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 1.7346 - accuracy: 0.5056\n",
      "Epoch 453/850\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 1.7058 - accuracy: 0.4933\n",
      "Epoch 454/850\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 1.6466 - accuracy: 0.5416\n",
      "Epoch 455/850\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.5609 - accuracy: 0.6000\n",
      "Epoch 456/850\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 1.5496 - accuracy: 0.5888\n",
      "Epoch 457/850\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 1.5722 - accuracy: 0.5843\n",
      "Epoch 458/850\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 1.5430 - accuracy: 0.5876\n",
      "Epoch 459/850\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 1.5118 - accuracy: 0.6000\n",
      "Epoch 460/850\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 1.4890 - accuracy: 0.6202\n",
      "Epoch 461/850\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 1.4860 - accuracy: 0.6169\n",
      "Epoch 462/850\n",
      "2/2 [==============================] - 0s 122ms/step - loss: 1.4634 - accuracy: 0.6258\n",
      "Epoch 463/850\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 1.4646 - accuracy: 0.6180\n",
      "Epoch 464/850\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 1.4306 - accuracy: 0.6371\n",
      "Epoch 465/850\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 1.4245 - accuracy: 0.6539\n",
      "Epoch 466/850\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 1.4239 - accuracy: 0.6472\n",
      "Epoch 467/850\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 1.4188 - accuracy: 0.6528\n",
      "Epoch 468/850\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 1.3976 - accuracy: 0.6506\n",
      "Epoch 469/850\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 1.3862 - accuracy: 0.6539\n",
      "Epoch 470/850\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 1.3888 - accuracy: 0.6528\n",
      "Epoch 471/850\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 1.3861 - accuracy: 0.6573\n",
      "Epoch 472/850\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 1.3789 - accuracy: 0.6596\n",
      "Epoch 473/850\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 1.3660 - accuracy: 0.6708\n",
      "Epoch 474/850\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.3676 - accuracy: 0.6697\n",
      "Epoch 475/850\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 1.3605 - accuracy: 0.6652\n",
      "Epoch 476/850\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 1.3527 - accuracy: 0.6663\n",
      "Epoch 477/850\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 1.3520 - accuracy: 0.6618\n",
      "Epoch 478/850\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 1.3453 - accuracy: 0.6674\n",
      "Epoch 479/850\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 1.3386 - accuracy: 0.6764\n",
      "Epoch 480/850\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 1.3343 - accuracy: 0.6843\n",
      "Epoch 481/850\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 1.3276 - accuracy: 0.6719\n",
      "Epoch 482/850\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 1.3217 - accuracy: 0.6787\n",
      "Epoch 483/850\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 1.3200 - accuracy: 0.6876\n",
      "Epoch 484/850\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 1.3121 - accuracy: 0.6843\n",
      "Epoch 485/850\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 1.3088 - accuracy: 0.6764\n",
      "Epoch 486/850\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 1.3055 - accuracy: 0.6798\n",
      "Epoch 487/850\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 1.3046 - accuracy: 0.6809\n",
      "Epoch 488/850\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 1.3006 - accuracy: 0.6798\n",
      "Epoch 489/850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 81ms/step - loss: 1.3009 - accuracy: 0.6843\n",
      "Epoch 490/850\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 1.2976 - accuracy: 0.6899\n",
      "Epoch 491/850\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 1.2921 - accuracy: 0.6876\n",
      "Epoch 492/850\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 1.2868 - accuracy: 0.6888\n",
      "Epoch 493/850\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.2840 - accuracy: 0.6843\n",
      "Epoch 494/850\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 1.2815 - accuracy: 0.6831\n",
      "Epoch 495/850\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 1.2795 - accuracy: 0.6798\n",
      "Epoch 496/850\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 1.2789 - accuracy: 0.6820\n",
      "Epoch 497/850\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 1.2803 - accuracy: 0.6820\n",
      "Epoch 498/850\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 1.2754 - accuracy: 0.6831\n",
      "Epoch 499/850\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 1.2765 - accuracy: 0.6843\n",
      "Epoch 500/850\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 1.2844 - accuracy: 0.6843\n",
      "Epoch 501/850\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 1.2786 - accuracy: 0.6798\n",
      "Epoch 502/850\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 1.2867 - accuracy: 0.6798\n",
      "Epoch 503/850\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.2924 - accuracy: 0.6742\n",
      "Epoch 504/850\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 1.2887 - accuracy: 0.6831\n",
      "Epoch 505/850\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 1.2925 - accuracy: 0.6775\n",
      "Epoch 506/850\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 1.2990 - accuracy: 0.6764\n",
      "Epoch 507/850\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 1.2797 - accuracy: 0.6787\n",
      "Epoch 508/850\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 1.2911 - accuracy: 0.6764\n",
      "Epoch 509/850\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 1.3118 - accuracy: 0.6719\n",
      "Epoch 510/850\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 1.3088 - accuracy: 0.6730\n",
      "Epoch 511/850\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 1.3320 - accuracy: 0.6607\n",
      "Epoch 512/850\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 1.3287 - accuracy: 0.6708\n",
      "Epoch 513/850\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 1.3291 - accuracy: 0.6640\n",
      "Epoch 514/850\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 1.3431 - accuracy: 0.6708\n",
      "Epoch 515/850\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 1.3415 - accuracy: 0.6517\n",
      "Epoch 516/850\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 1.3212 - accuracy: 0.6674\n",
      "Epoch 517/850\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 1.3250 - accuracy: 0.6551\n",
      "Epoch 518/850\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 1.3430 - accuracy: 0.6562\n",
      "Epoch 519/850\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 1.3276 - accuracy: 0.6483\n",
      "Epoch 520/850\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 1.3381 - accuracy: 0.6517\n",
      "Epoch 521/850\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 1.3614 - accuracy: 0.6573\n",
      "Epoch 522/850\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 1.3507 - accuracy: 0.6494\n",
      "Epoch 523/850\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 1.3188 - accuracy: 0.6528\n",
      "Epoch 524/850\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 1.2846 - accuracy: 0.6697\n",
      "Epoch 525/850\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 1.2858 - accuracy: 0.6742\n",
      "Epoch 526/850\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 1.2524 - accuracy: 0.6798\n",
      "Epoch 527/850\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 1.2495 - accuracy: 0.6787\n",
      "Epoch 528/850\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 1.2566 - accuracy: 0.6719\n",
      "Epoch 529/850\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 1.2347 - accuracy: 0.6865\n",
      "Epoch 530/850\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 1.2426 - accuracy: 0.6809\n",
      "Epoch 531/850\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 1.2281 - accuracy: 0.6876\n",
      "Epoch 532/850\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 1.2159 - accuracy: 0.6899\n",
      "Epoch 533/850\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 1.2116 - accuracy: 0.6899\n",
      "Epoch 534/850\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 1.2079 - accuracy: 0.6865\n",
      "Epoch 535/850\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 1.1869 - accuracy: 0.7000\n",
      "Epoch 536/850\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 1.1829 - accuracy: 0.7067\n",
      "Epoch 537/850\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 1.1803 - accuracy: 0.7079\n",
      "Epoch 538/850\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 1.1724 - accuracy: 0.7011\n",
      "Epoch 539/850\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 1.1697 - accuracy: 0.7056\n",
      "Epoch 540/850\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 1.1654 - accuracy: 0.7034\n",
      "Epoch 541/850\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 1.1603 - accuracy: 0.7045\n",
      "Epoch 542/850\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 1.1538 - accuracy: 0.7101\n",
      "Epoch 543/850\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 1.1520 - accuracy: 0.7056\n",
      "Epoch 544/850\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 1.1536 - accuracy: 0.7067\n",
      "Epoch 545/850\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.1547 - accuracy: 0.7034\n",
      "Epoch 546/850\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 1.1623 - accuracy: 0.7034\n",
      "Epoch 547/850\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 1.1623 - accuracy: 0.7000\n",
      "Epoch 548/850\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 1.1750 - accuracy: 0.6989\n",
      "Epoch 549/850\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 1.1730 - accuracy: 0.7011\n",
      "Epoch 550/850\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 1.1776 - accuracy: 0.7034\n",
      "Epoch 551/850\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 1.1880 - accuracy: 0.6876\n",
      "Epoch 552/850\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.1868 - accuracy: 0.6899\n",
      "Epoch 553/850\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 1.1631 - accuracy: 0.6966\n",
      "Epoch 554/850\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 1.1763 - accuracy: 0.6989\n",
      "Epoch 555/850\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.1819 - accuracy: 0.6978\n",
      "Epoch 556/850\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 1.1842 - accuracy: 0.6910\n",
      "Epoch 557/850\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 1.2062 - accuracy: 0.6775\n",
      "Epoch 558/850\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 1.2114 - accuracy: 0.6730\n",
      "Epoch 559/850\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 1.2032 - accuracy: 0.6921\n",
      "Epoch 560/850\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 1.1982 - accuracy: 0.6854\n",
      "Epoch 561/850\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 1.1932 - accuracy: 0.6843\n",
      "Epoch 562/850\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 1.1760 - accuracy: 0.6831\n",
      "Epoch 563/850\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 1.1556 - accuracy: 0.7011\n",
      "Epoch 564/850\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 1.1475 - accuracy: 0.6978\n",
      "Epoch 565/850\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 1.1344 - accuracy: 0.7135\n",
      "Epoch 566/850\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 1.1353 - accuracy: 0.7022\n",
      "Epoch 567/850\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 1.1201 - accuracy: 0.7079\n",
      "Epoch 568/850\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 1.1258 - accuracy: 0.7157\n",
      "Epoch 569/850\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 1.1107 - accuracy: 0.7067\n",
      "Epoch 570/850\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 1.0987 - accuracy: 0.7112\n",
      "Epoch 571/850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 84ms/step - loss: 1.0992 - accuracy: 0.7303\n",
      "Epoch 572/850\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 1.0904 - accuracy: 0.7258\n",
      "Epoch 573/850\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 1.0880 - accuracy: 0.7236\n",
      "Epoch 574/850\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 1.0782 - accuracy: 0.7236\n",
      "Epoch 575/850\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 1.0802 - accuracy: 0.7180\n",
      "Epoch 576/850\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 1.0755 - accuracy: 0.7247\n",
      "Epoch 577/850\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 1.0665 - accuracy: 0.7247\n",
      "Epoch 578/850\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 1.0703 - accuracy: 0.7303\n",
      "Epoch 579/850\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 1.0648 - accuracy: 0.7303\n",
      "Epoch 580/850\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 1.0582 - accuracy: 0.7292\n",
      "Epoch 581/850\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 1.0545 - accuracy: 0.7326\n",
      "Epoch 582/850\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 1.0633 - accuracy: 0.7315\n",
      "Epoch 583/850\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 1.0691 - accuracy: 0.7191\n",
      "Epoch 584/850\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 1.0577 - accuracy: 0.7258\n",
      "Epoch 585/850\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 1.0623 - accuracy: 0.7315\n",
      "Epoch 586/850\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 1.0516 - accuracy: 0.7348\n",
      "Epoch 587/850\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 1.0599 - accuracy: 0.7281\n",
      "Epoch 588/850\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 1.0571 - accuracy: 0.7247\n",
      "Epoch 589/850\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 1.0639 - accuracy: 0.7157\n",
      "Epoch 590/850\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 1.0437 - accuracy: 0.7292\n",
      "Epoch 591/850\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.0436 - accuracy: 0.7404\n",
      "Epoch 592/850\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 1.0390 - accuracy: 0.7416\n",
      "Epoch 593/850\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 1.0390 - accuracy: 0.7326\n",
      "Epoch 594/850\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 1.0336 - accuracy: 0.7382\n",
      "Epoch 595/850\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 1.0354 - accuracy: 0.7326\n",
      "Epoch 596/850\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 1.0324 - accuracy: 0.7393\n",
      "Epoch 597/850\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 1.0274 - accuracy: 0.7236\n",
      "Epoch 598/850\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.0365 - accuracy: 0.7292\n",
      "Epoch 599/850\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 1.0256 - accuracy: 0.7416\n",
      "Epoch 600/850\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 1.0338 - accuracy: 0.7360\n",
      "Epoch 601/850\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 1.0394 - accuracy: 0.7315\n",
      "Epoch 602/850\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 1.0235 - accuracy: 0.7382\n",
      "Epoch 603/850\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 1.0196 - accuracy: 0.7315\n",
      "Epoch 604/850\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 1.0085 - accuracy: 0.7303\n",
      "Epoch 605/850\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 1.0019 - accuracy: 0.7371\n",
      "Epoch 606/850\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 1.0115 - accuracy: 0.7315\n",
      "Epoch 607/850\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 1.0092 - accuracy: 0.7303\n",
      "Epoch 608/850\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 1.0058 - accuracy: 0.7416\n",
      "Epoch 609/850\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 1.0008 - accuracy: 0.7404\n",
      "Epoch 610/850\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.9988 - accuracy: 0.7461\n",
      "Epoch 611/850\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.9831 - accuracy: 0.7461\n",
      "Epoch 612/850\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.9996 - accuracy: 0.7337\n",
      "Epoch 613/850\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.9833 - accuracy: 0.7393\n",
      "Epoch 614/850\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.9768 - accuracy: 0.7494\n",
      "Epoch 615/850\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.9743 - accuracy: 0.7517\n",
      "Epoch 616/850\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.9733 - accuracy: 0.7371\n",
      "Epoch 617/850\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.9714 - accuracy: 0.7438\n",
      "Epoch 618/850\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.9709 - accuracy: 0.7416\n",
      "Epoch 619/850\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.9655 - accuracy: 0.7517\n",
      "Epoch 620/850\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.9546 - accuracy: 0.7494\n",
      "Epoch 621/850\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.9562 - accuracy: 0.7506\n",
      "Epoch 622/850\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.9534 - accuracy: 0.7438\n",
      "Epoch 623/850\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.9514 - accuracy: 0.7517\n",
      "Epoch 624/850\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.9574 - accuracy: 0.7506\n",
      "Epoch 625/850\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.9501 - accuracy: 0.7461\n",
      "Epoch 626/850\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.9403 - accuracy: 0.7551\n",
      "Epoch 627/850\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.9392 - accuracy: 0.7506\n",
      "Epoch 628/850\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.9386 - accuracy: 0.7584\n",
      "Epoch 629/850\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.9457 - accuracy: 0.7562\n",
      "Epoch 630/850\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.9467 - accuracy: 0.7618\n",
      "Epoch 631/850\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.9376 - accuracy: 0.7539\n",
      "Epoch 632/850\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.9293 - accuracy: 0.7596\n",
      "Epoch 633/850\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.9245 - accuracy: 0.7584\n",
      "Epoch 634/850\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.9277 - accuracy: 0.7584\n",
      "Epoch 635/850\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.9220 - accuracy: 0.7584\n",
      "Epoch 636/850\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.9212 - accuracy: 0.7551\n",
      "Epoch 637/850\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.9078 - accuracy: 0.7674\n",
      "Epoch 638/850\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.9024 - accuracy: 0.7697\n",
      "Epoch 639/850\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.9042 - accuracy: 0.7629\n",
      "Epoch 640/850\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.8998 - accuracy: 0.7663\n",
      "Epoch 641/850\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.9013 - accuracy: 0.7562\n",
      "Epoch 642/850\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.9103 - accuracy: 0.7652\n",
      "Epoch 643/850\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.9101 - accuracy: 0.7640\n",
      "Epoch 644/850\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.9143 - accuracy: 0.7640\n",
      "Epoch 645/850\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.9153 - accuracy: 0.7584\n",
      "Epoch 646/850\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.9112 - accuracy: 0.7584\n",
      "Epoch 647/850\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.9063 - accuracy: 0.7573\n",
      "Epoch 648/850\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.8944 - accuracy: 0.7618\n",
      "Epoch 649/850\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.8899 - accuracy: 0.7674\n",
      "Epoch 650/850\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 0.8864 - accuracy: 0.7764\n",
      "Epoch 651/850\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.8864 - accuracy: 0.7697\n",
      "Epoch 652/850\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 0.8786 - accuracy: 0.7640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 653/850\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.8758 - accuracy: 0.7697\n",
      "Epoch 654/850\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 0.8721 - accuracy: 0.7742\n",
      "Epoch 655/850\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.8680 - accuracy: 0.7742\n",
      "Epoch 656/850\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.8668 - accuracy: 0.7652\n",
      "Epoch 657/850\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.8612 - accuracy: 0.7764\n",
      "Epoch 658/850\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.8569 - accuracy: 0.7719\n",
      "Epoch 659/850\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.8571 - accuracy: 0.7674\n",
      "Epoch 660/850\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 0.8596 - accuracy: 0.7730\n",
      "Epoch 661/850\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.8598 - accuracy: 0.7708\n",
      "Epoch 662/850\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.8591 - accuracy: 0.7730\n",
      "Epoch 663/850\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.8528 - accuracy: 0.7742\n",
      "Epoch 664/850\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.8488 - accuracy: 0.7809\n",
      "Epoch 665/850\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.8494 - accuracy: 0.7742\n",
      "Epoch 666/850\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.8406 - accuracy: 0.7775\n",
      "Epoch 667/850\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.8463 - accuracy: 0.7708\n",
      "Epoch 668/850\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.8500 - accuracy: 0.7753\n",
      "Epoch 669/850\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.8415 - accuracy: 0.7753\n",
      "Epoch 670/850\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.8419 - accuracy: 0.7674\n",
      "Epoch 671/850\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.8344 - accuracy: 0.7764\n",
      "Epoch 672/850\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.8338 - accuracy: 0.7843\n",
      "Epoch 673/850\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 0.8284 - accuracy: 0.7798\n",
      "Epoch 674/850\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.8339 - accuracy: 0.7742\n",
      "Epoch 675/850\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 0.8306 - accuracy: 0.7831\n",
      "Epoch 676/850\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 0.8296 - accuracy: 0.7809\n",
      "Epoch 677/850\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 0.8351 - accuracy: 0.7798\n",
      "Epoch 678/850\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.8307 - accuracy: 0.7742\n",
      "Epoch 679/850\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 0.8264 - accuracy: 0.7764\n",
      "Epoch 680/850\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.8248 - accuracy: 0.7809\n",
      "Epoch 681/850\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.8467 - accuracy: 0.7809\n",
      "Epoch 682/850\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.8255 - accuracy: 0.7753\n",
      "Epoch 683/850\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.8236 - accuracy: 0.7719\n",
      "Epoch 684/850\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.8232 - accuracy: 0.7820\n",
      "Epoch 685/850\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 0.8225 - accuracy: 0.7843\n",
      "Epoch 686/850\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 0.8152 - accuracy: 0.7843\n",
      "Epoch 687/850\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 0.8240 - accuracy: 0.7708\n",
      "Epoch 688/850\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.8102 - accuracy: 0.7820\n",
      "Epoch 689/850\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.8086 - accuracy: 0.7787\n",
      "Epoch 690/850\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.8045 - accuracy: 0.7798\n",
      "Epoch 691/850\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.8117 - accuracy: 0.7831\n",
      "Epoch 692/850\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.8121 - accuracy: 0.7910\n",
      "Epoch 693/850\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.8075 - accuracy: 0.7753\n",
      "Epoch 694/850\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.8012 - accuracy: 0.7820\n",
      "Epoch 695/850\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.8098 - accuracy: 0.7809\n",
      "Epoch 696/850\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.8069 - accuracy: 0.7888\n",
      "Epoch 697/850\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.8028 - accuracy: 0.7820\n",
      "Epoch 698/850\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.8059 - accuracy: 0.7775\n",
      "Epoch 699/850\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.8122 - accuracy: 0.7843\n",
      "Epoch 700/850\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.7997 - accuracy: 0.7820\n",
      "Epoch 701/850\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.7942 - accuracy: 0.7854\n",
      "Epoch 702/850\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.8244 - accuracy: 0.7820\n",
      "Epoch 703/850\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 0.8244 - accuracy: 0.7730\n",
      "Epoch 704/850\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.8326 - accuracy: 0.7607\n",
      "Epoch 705/850\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 0.8181 - accuracy: 0.7775\n",
      "Epoch 706/850\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.8655 - accuracy: 0.7584\n",
      "Epoch 707/850\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 1.0112 - accuracy: 0.7146\n",
      "Epoch 708/850\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 1.0216 - accuracy: 0.7056\n",
      "Epoch 709/850\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 1.0654 - accuracy: 0.7011\n",
      "Epoch 710/850\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 0.9954 - accuracy: 0.7011\n",
      "Epoch 711/850\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 1.0217 - accuracy: 0.6944\n",
      "Epoch 712/850\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 1.1753 - accuracy: 0.6472\n",
      "Epoch 713/850\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 1.1556 - accuracy: 0.6596\n",
      "Epoch 714/850\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 1.1994 - accuracy: 0.6393\n",
      "Epoch 715/850\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 1.2239 - accuracy: 0.6225\n",
      "Epoch 716/850\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 1.2134 - accuracy: 0.6213\n",
      "Epoch 717/850\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 1.2926 - accuracy: 0.6022\n",
      "Epoch 718/850\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 1.3108 - accuracy: 0.6056\n",
      "Epoch 719/850\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 1.3671 - accuracy: 0.5831\n",
      "Epoch 720/850\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 1.3917 - accuracy: 0.5899\n",
      "Epoch 721/850\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 1.3690 - accuracy: 0.5742\n",
      "Epoch 722/850\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 1.3861 - accuracy: 0.5944\n",
      "Epoch 723/850\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 1.3100 - accuracy: 0.5888\n",
      "Epoch 724/850\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 1.2193 - accuracy: 0.6213\n",
      "Epoch 725/850\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 1.1960 - accuracy: 0.6180\n",
      "Epoch 726/850\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 1.0653 - accuracy: 0.6809\n",
      "Epoch 727/850\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 1.0376 - accuracy: 0.7067\n",
      "Epoch 728/850\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 1.0283 - accuracy: 0.6933\n",
      "Epoch 729/850\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.9947 - accuracy: 0.7258\n",
      "Epoch 730/850\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 1.0203 - accuracy: 0.6966\n",
      "Epoch 731/850\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 1.0383 - accuracy: 0.6944\n",
      "Epoch 732/850\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.9737 - accuracy: 0.6944\n",
      "Epoch 733/850\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 1.0095 - accuracy: 0.6843\n",
      "Epoch 734/850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 114ms/step - loss: 0.9875 - accuracy: 0.6921\n",
      "Epoch 735/850\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.9164 - accuracy: 0.7472\n",
      "Epoch 736/850\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.9578 - accuracy: 0.7202\n",
      "Epoch 737/850\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.9555 - accuracy: 0.7090\n",
      "Epoch 738/850\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.9049 - accuracy: 0.7393\n",
      "Epoch 739/850\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.8454 - accuracy: 0.7584\n",
      "Epoch 740/850\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.8434 - accuracy: 0.7640\n",
      "Epoch 741/850\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.8361 - accuracy: 0.7584\n",
      "Epoch 742/850\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.8247 - accuracy: 0.7753\n",
      "Epoch 743/850\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 0.8109 - accuracy: 0.7663\n",
      "Epoch 744/850\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.7922 - accuracy: 0.7910\n",
      "Epoch 745/850\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 0.8056 - accuracy: 0.7685\n",
      "Epoch 746/850\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.7893 - accuracy: 0.7831\n",
      "Epoch 747/850\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.7632 - accuracy: 0.7899\n",
      "Epoch 748/850\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 0.7537 - accuracy: 0.7843\n",
      "Epoch 749/850\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.7491 - accuracy: 0.8011\n",
      "Epoch 750/850\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 0.7420 - accuracy: 0.7955\n",
      "Epoch 751/850\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.7333 - accuracy: 0.7989\n",
      "Epoch 752/850\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.7243 - accuracy: 0.8000\n",
      "Epoch 753/850\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.7095 - accuracy: 0.8101\n",
      "Epoch 754/850\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.7108 - accuracy: 0.8034\n",
      "Epoch 755/850\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 0.7034 - accuracy: 0.8169\n",
      "Epoch 756/850\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.6990 - accuracy: 0.8112\n",
      "Epoch 757/850\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.6941 - accuracy: 0.8169\n",
      "Epoch 758/850\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.6867 - accuracy: 0.8124\n",
      "Epoch 759/850\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 0.6836 - accuracy: 0.8101\n",
      "Epoch 760/850\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.6813 - accuracy: 0.8191\n",
      "Epoch 761/850\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.6787 - accuracy: 0.8191\n",
      "Epoch 762/850\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.6745 - accuracy: 0.8191\n",
      "Epoch 763/850\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.6674 - accuracy: 0.8180\n",
      "Epoch 764/850\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.6595 - accuracy: 0.8202\n",
      "Epoch 765/850\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.6583 - accuracy: 0.8225\n",
      "Epoch 766/850\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.6572 - accuracy: 0.8236\n",
      "Epoch 767/850\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.6502 - accuracy: 0.8281\n",
      "Epoch 768/850\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.6495 - accuracy: 0.8303\n",
      "Epoch 769/850\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.6445 - accuracy: 0.8292\n",
      "Epoch 770/850\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.6449 - accuracy: 0.8303\n",
      "Epoch 771/850\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.6434 - accuracy: 0.8225\n",
      "Epoch 772/850\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.6404 - accuracy: 0.8270\n",
      "Epoch 773/850\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.6373 - accuracy: 0.8326\n",
      "Epoch 774/850\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.6354 - accuracy: 0.8292\n",
      "Epoch 775/850\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.6348 - accuracy: 0.8315\n",
      "Epoch 776/850\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.6349 - accuracy: 0.8247\n",
      "Epoch 777/850\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.6276 - accuracy: 0.8371\n",
      "Epoch 778/850\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.6280 - accuracy: 0.8315\n",
      "Epoch 779/850\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.6269 - accuracy: 0.8348\n",
      "Epoch 780/850\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.6255 - accuracy: 0.8348\n",
      "Epoch 781/850\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.6220 - accuracy: 0.8371\n",
      "Epoch 782/850\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.6203 - accuracy: 0.8438\n",
      "Epoch 783/850\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.6198 - accuracy: 0.8348\n",
      "Epoch 784/850\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.6231 - accuracy: 0.8326\n",
      "Epoch 785/850\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.6237 - accuracy: 0.8348\n",
      "Epoch 786/850\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.6233 - accuracy: 0.8270\n",
      "Epoch 787/850\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.6320 - accuracy: 0.8315\n",
      "Epoch 788/850\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.6177 - accuracy: 0.8281\n",
      "Epoch 789/850\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 0.6213 - accuracy: 0.8303\n",
      "Epoch 790/850\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.6170 - accuracy: 0.8348\n",
      "Epoch 791/850\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.6145 - accuracy: 0.8326\n",
      "Epoch 792/850\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.6111 - accuracy: 0.8371\n",
      "Epoch 793/850\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.6079 - accuracy: 0.8404\n",
      "Epoch 794/850\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.6135 - accuracy: 0.8326\n",
      "Epoch 795/850\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.6035 - accuracy: 0.8371\n",
      "Epoch 796/850\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.6024 - accuracy: 0.8360\n",
      "Epoch 797/850\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.6015 - accuracy: 0.8393\n",
      "Epoch 798/850\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.6022 - accuracy: 0.8404\n",
      "Epoch 799/850\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.6008 - accuracy: 0.8371\n",
      "Epoch 800/850\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.5979 - accuracy: 0.8416\n",
      "Epoch 801/850\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 0.6008 - accuracy: 0.8382\n",
      "Epoch 802/850\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.6030 - accuracy: 0.8404\n",
      "Epoch 803/850\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.5954 - accuracy: 0.8472\n",
      "Epoch 804/850\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.5962 - accuracy: 0.8472\n",
      "Epoch 805/850\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.5941 - accuracy: 0.8472\n",
      "Epoch 806/850\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.5913 - accuracy: 0.8393\n",
      "Epoch 807/850\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.5865 - accuracy: 0.8427\n",
      "Epoch 808/850\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.5854 - accuracy: 0.8494\n",
      "Epoch 809/850\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.5833 - accuracy: 0.8472\n",
      "Epoch 810/850\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.5799 - accuracy: 0.8483\n",
      "Epoch 811/850\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.5829 - accuracy: 0.8494\n",
      "Epoch 812/850\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.5756 - accuracy: 0.8494\n",
      "Epoch 813/850\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.5765 - accuracy: 0.8427\n",
      "Epoch 814/850\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.5725 - accuracy: 0.8483\n",
      "Epoch 815/850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 118ms/step - loss: 0.5722 - accuracy: 0.8506\n",
      "Epoch 816/850\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.5734 - accuracy: 0.8506\n",
      "Epoch 817/850\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.5680 - accuracy: 0.8584\n",
      "Epoch 818/850\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 0.5769 - accuracy: 0.8494\n",
      "Epoch 819/850\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.5776 - accuracy: 0.8438\n",
      "Epoch 820/850\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.5749 - accuracy: 0.8472\n",
      "Epoch 821/850\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.5759 - accuracy: 0.8483\n",
      "Epoch 822/850\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.5651 - accuracy: 0.8539\n",
      "Epoch 823/850\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.5615 - accuracy: 0.8539\n",
      "Epoch 824/850\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.5600 - accuracy: 0.8539\n",
      "Epoch 825/850\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.5632 - accuracy: 0.8517\n",
      "Epoch 826/850\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.5695 - accuracy: 0.8461\n",
      "Epoch 827/850\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.5645 - accuracy: 0.8517\n",
      "Epoch 828/850\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.5624 - accuracy: 0.8483\n",
      "Epoch 829/850\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.5697 - accuracy: 0.8404\n",
      "Epoch 830/850\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.5617 - accuracy: 0.8506\n",
      "Epoch 831/850\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.5558 - accuracy: 0.8562\n",
      "Epoch 832/850\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.5454 - accuracy: 0.8652\n",
      "Epoch 833/850\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.5435 - accuracy: 0.8562\n",
      "Epoch 834/850\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.5414 - accuracy: 0.8539\n",
      "Epoch 835/850\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.5419 - accuracy: 0.8618\n",
      "Epoch 836/850\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 0.5412 - accuracy: 0.8584\n",
      "Epoch 837/850\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.5359 - accuracy: 0.8618\n",
      "Epoch 838/850\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.5403 - accuracy: 0.8618\n",
      "Epoch 839/850\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.5348 - accuracy: 0.8618\n",
      "Epoch 840/850\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.5392 - accuracy: 0.8517\n",
      "Epoch 841/850\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.5379 - accuracy: 0.8562\n",
      "Epoch 842/850\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.5286 - accuracy: 0.8640\n",
      "Epoch 843/850\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.5331 - accuracy: 0.8573\n",
      "Epoch 844/850\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.5277 - accuracy: 0.8562\n",
      "Epoch 845/850\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 0.5241 - accuracy: 0.8573\n",
      "Epoch 846/850\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.5162 - accuracy: 0.8618\n",
      "Epoch 847/850\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.5157 - accuracy: 0.8663\n",
      "Epoch 848/850\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.5152 - accuracy: 0.8596\n",
      "Epoch 849/850\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.5136 - accuracy: 0.8742\n",
      "Epoch 850/850\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.5111 - accuracy: 0.8697\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21be3e5c790>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y,epochs=850,batch_size=512,verbose=1,validation_batch_size=.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22670837",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "4e0bc2d7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e80461c2",
   "metadata": {},
   "source": [
    "**The process was faster because we extracted only 2000 charachters from the original corpus(a=a[:2000]) or else it would take a lot of time for this code to run**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f339332e",
   "metadata": {},
   "source": [
    "**If we want better accuracy our epochs should also be more but it would take a long time for the code to run**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43320c77",
   "metadata": {},
   "source": [
    "**<font color='green'> We got 86.97% accuracy</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5441be02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ff9ab1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c70e4c01",
   "metadata": {},
   "source": [
    "**<font color='blue'> Lets save the model now</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "503ab82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Novel_big.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c399e4a8",
   "metadata": {},
   "source": [
    "**<font color='blue'> Lets save the tokeniser as well</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4125e865",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(tok,open('Novel_tok','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40babf8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c536432",
   "metadata": {},
   "source": [
    "### <div class='alert alert-info'><font color='black'>Text Generation</font></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "752495cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fc1e0338",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model,tokenizer,seq_len,seed_text,num_gen_words):\n",
    "    \n",
    "    '''\n",
    "    model is the model which we have saved \n",
    "    tokenizer is the tokenizer which we have worked till now and has knowledge about the vocabulary\n",
    "    seq len is basically the sequences of 10 words and the 11th word we are predicting\n",
    "    seed text is basically the input text or the text with which we are going to start of our work\n",
    "    num_gen_words is the number of generated words we want after giving the input text\n",
    "    '''\n",
    "    \n",
    "    output_text=[]\n",
    "    input_text=seed_text\n",
    "    for i in range(num_gen_words):\n",
    "        encoded_text=tokenizer.texts_to_sequences([input_text])[0]\n",
    "        \n",
    "        # We are taking the input text and encoding it to the sequences of numbers just like how we did before\n",
    "        \n",
    "       \n",
    "        pad_encoded=pad_sequences([encoded_text],maxlen=seq_len)\n",
    "     \n",
    "        # This is making sure if we pass down a very long seed text it will automatically pad it to 10 tokens\n",
    "        #since we are working with only 10 training tokens\n",
    "        #Or if we pass a very short seed text then it will pad it up so that it can reach 10 tokens   \n",
    "   \n",
    "        predict_x=model.predict(pad_encoded) \n",
    "        pred_word_ind=np.argmax(predict_x,axis=1)[0]\n",
    "  \n",
    "         # It will predict the index like for example 12% probability that the next word is \"looming\" or \n",
    "         #32% probability that the next word is \"years\"\n",
    "  \n",
    "        pred_word=tokenizer.index_word[pred_word_ind]\n",
    "     \n",
    "        #This will make us get the actual word with the help of the index\n",
    "        \n",
    "        input_text=' '+pred_word\n",
    "        \n",
    "        output_text.append(pred_word)      \n",
    "    \n",
    "    return ' '.join(output_text)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc5d5b1",
   "metadata": {},
   "source": [
    "**Lets take any random text sequence from our data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400c8a93",
   "metadata": {},
   "source": [
    "I am choosing the 5th text sequence you can choose any as you desire<br>(there is no specific reason for me to choose 5th sentence I'm just choosing randomly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3e3c3814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['me',\n",
       " 'ishmael',\n",
       " 'some',\n",
       " 'years',\n",
       " 'ago',\n",
       " 'never',\n",
       " 'mind',\n",
       " 'how',\n",
       " 'long',\n",
       " 'precisely',\n",
       " 'having']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_sequence[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e2f43835",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_text=' '.join(text_sequence[14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a71539e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'having little or no money in my purse and nothing particular'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bbc7adc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a129660f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=models.load_model('Novel_big.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e0649c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=load(open('Novel_tok','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9cd9565f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 681ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'to here all here all'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model,tokenizer,seq_len,seed_text=seed_text,num_gen_words=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f36d83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a80e0a4e",
   "metadata": {},
   "source": [
    "### **<font color='green'>Here we go we got our generated words</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb9f0e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bad26bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dfc0ea3a",
   "metadata": {},
   "source": [
    "**Now if we want to any random text sequence from our data and check the new words generated<br>\n",
    "we have to use the random function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdf86fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6c6f5222",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random_pick = random.randint(0,len(text_sequence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8cea91a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed_text = text_sequence[random_pick]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "599cb1b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['thousands', 'upon', 'thousands', 'of', 'mortal', 'men', 'fixed', 'in', 'ocean', 'reveries', 'some']\n"
     ]
    }
   ],
   "source": [
    "print(random_seed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "87a931b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thousands upon thousands of mortal men fixed in ocean reveries some'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_text = ' '.join(random_seed_text)\n",
    "seed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e3bbc200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'leaning here all here all'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model,tokenizer,seq_len,seed_text=seed_text,num_gen_words=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ee4d7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f2b4f245",
   "metadata": {},
   "source": [
    "## <font color='green'> Hence we have generated the next word by prediction </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa13ef57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
